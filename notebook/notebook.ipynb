{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e6246c30-a1d4-4746-ba9a-9d68d298191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile_from():\n",
    "    skills = [\n",
    "        'Agentic AI', \n",
    "        'Retrieval Augmented Generation (RAG)', \n",
    "        'Large Language Models (LLMs)', \n",
    "        'LangChain', \n",
    "        'Django',\n",
    "        'LSTM',\n",
    "        'Flask',\n",
    "        'Transformers',\n",
    "        'RNN',\n",
    "        'TensorFlow',\n",
    "        'Supervised Learning',\n",
    "        'Unsupervised Learning',\n",
    "        'Pytorch',\n",
    "        'CNN',\n",
    "        'DBMS',\n",
    "        'DSA',\n",
    "        'Statistics',\n",
    "        'SQL',\n",
    "        'AI',\n",
    "        'Linear Algebra',\n",
    "        'Calculus',\n",
    "        'PCA',\n",
    "        'Python',\n",
    "        'Seaborn',\n",
    "        'Pandas',\n",
    "        'Numpy',\n",
    "        'Matplotlib',\n",
    "        'Scikit-learn',\n",
    "        'Data Analytics',\n",
    "        'Data Science',\n",
    "        'Machine Learning',\n",
    "        'Jupyter Notebook',\n",
    "        'Git'\n",
    "    ]\n",
    "    certifications = [\n",
    "        {\n",
    "            'name' : 'Google Advanced Data Analytics',\n",
    "            'organization' : 'Google'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'IBM Data Science Professional Certificate',\n",
    "            'organization' : 'IBM'\n",
    "        }, \n",
    "        {\n",
    "            'name' : 'IBM RAG and Agentic AI: Build Next-Gen AI Systems',\n",
    "            'organization' : 'IBM'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'Deep Learning',\n",
    "            'organization' : 'DeepLearningAI'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'Machine Learning',\n",
    "            'organization' : 'DeepLearningAI'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'Mathematics for Machine Learning Specialization',\n",
    "            'organization' : 'Imperial College London'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'Mathematics for Machine Learning and Data Science',\n",
    "            'organization' : 'DeepLearning.AI'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'Python for Everybody Specialization',\n",
    "            'organization' : 'University of Michigan'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    projects = [\n",
    "        {\n",
    "            'name' : 'BiasBusterAI: Text Bias Detection System',\n",
    "            'start_date' : 'October 2025',\n",
    "            'end_date' : 'October 2025',\n",
    "            'description' : 'Developed AI web app detecting biases (race, gender, profession, religion) with Bidirectional LSTM with Self Attention, achieving ~98% accuracy via TensorFlow. Created Flask interface with Plotly for real-time visualization of bias probabilities and attention weights. https://github.com/sheb1lmsp/BiasBusterAI'\n",
    "        },\n",
    "        {\n",
    "            'name' : 'SmartAttend: An Automated Attendance Management System',\n",
    "            'start_date' : 'May 2025',\n",
    "            'start_date' : 'August 2025',\n",
    "            'description' : 'Developed a smart attendance management system using facial recognition to automate classroom attendance tracking. Leveraged PyTorch, MTCNN, and InceptionResNetV1 to build and train machine learning models for accurate face detection and recognition. Integrated the ML pipeline with a Django web application, featuring role-based dashboards for admins, teachers, and students. Enabled efficient attendance marking via group photos, streamlining academic workflows. https://github.com/sheb1lmsp/smart_attend'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    education = [\n",
    "        {\n",
    "            'degree' : 'Bachelor of Computer Applications',\n",
    "            'university' : 'Bangalore University',\n",
    "            'start_date' : 'August 2022',\n",
    "            'end_date' : 'June 2025',\n",
    "            'cgpa' : '8.82'\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    experience = [\n",
    "        {\n",
    "            'title' : '',\n",
    "            'employment_type' : '',\n",
    "            'company' : '',\n",
    "            'start_date' : '',\n",
    "            'end_date' : '',\n",
    "            'location' : '',\n",
    "            'description' : ''\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {'education' : education, 'certifications' : certifications, 'projects' : projects, 'skills' : skills, 'experience' : experience}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae3b40-b7f6-4fbf-876f-7e53c4643ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2c5b65a7-30d0-4af5-aff3-ec7becc34bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288dbfb9-93ea-4c48-b0cc-e89c3909b016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "81bebe72-c7ae-4e20-bc3c-5d9c14591938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, List, Dict, Optional, Any\n",
    "\n",
    "class Project(TypedDict):\n",
    "    name: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    description: str\n",
    "\n",
    "class Certification(TypedDict):\n",
    "    name: str\n",
    "    organization: str\n",
    "\n",
    "class Education(TypedDict):\n",
    "    degree: str\n",
    "    university: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    cgpa: float\n",
    "\n",
    "class Experience(TypedDict):\n",
    "    title: str\n",
    "    employment_type: str\n",
    "    company: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    location: str\n",
    "    description: str\n",
    "\n",
    "class State(TypedDict):\n",
    "    input_text: str\n",
    "    agent_action: Optional[\n",
    "        Literal[\n",
    "            \"course_recommender\",\n",
    "            \"project_recommender\",\n",
    "            \"interview_coach\",\n",
    "            \"learning_path_advisor\",\n",
    "            \"resume_builder\",\n",
    "            \"skill_analyzer\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    skills: Optional[List[str]]\n",
    "    certifications: Optional[List[Certification]]\n",
    "    projects: Optional[List[Project]]\n",
    "    education: Optional[List[Education]]\n",
    "    experience: Optional[List[Experience]]\n",
    "\n",
    "    response: Optional[str]\n",
    "    final_output: Optional[str]\n",
    "\n",
    "    metadata: Optional[Dict]\n",
    "    resume_text: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04017a51-ecd0-47c5-b249-783d5e8f677b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "17e3f8ce-8724-437b-8765-919b669b9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgentType(BaseModel):\n",
    "    agent_name: str = Field(description=\"The name of the agent that should handle this query\")\n",
    "\n",
    "def router(state: State) -> State:\n",
    "    \"\"\"Router function for CareerGraph AI â€” decides which agent to use based on input_text.\"\"\"\n",
    "    \n",
    "    router_prompt = ChatPromptTemplate.from_messages(\n",
    "       [(\n",
    "           \"system\",\n",
    "           \"\"\"\n",
    "           You are the RouterAgent for CareerGraph AI â€” an intelligent, LLM-powered career assistant.\n",
    "           \n",
    "           Your task:\n",
    "           - Read the user's query carefully.\n",
    "           - Determine which specialized agent should handle it.\n",
    "           \n",
    "           Return 'only one' of the following agent names as a 'plain string' (no punctuation, no explanation):\n",
    "           \n",
    "           1. \"skill_analyzer\" â†’ When the user talks about skills, strengths, weaknesses, or what theyâ€™re good at.\n",
    "           2. \"career_advisor\" â†’ When the user asks about job roles, next career moves, or suitable positions.\n",
    "           3. \"project_recommender\" â†’ When the user asks for project ideas, feedback, or inspiration for new projects.\n",
    "           4. \"course_recommender\" â†’ When the user asks for learning resources, courses, or certifications.\n",
    "           5. \"learning_path_advisor\" â†’ When the user wants a structured roadmap or skill-learning order.\n",
    "           6. \"resume_builder\" â†’ When the user wants to create, optimize, or improve their resume.\n",
    "           7. \"interview_coach\" â†’ When the user wants interview preparation, practice questions, or feedback.\n",
    "           \n",
    "           Output format:\n",
    "           Return 'only' the agent name as a raw string like: skill_analyzer\n",
    "           \"\"\"\n",
    "       ),\n",
    "        (\"human\",\"User query: {input_text}\")\n",
    "       ]\n",
    "    )\n",
    "\n",
    "    chain = router_prompt | llm.with_structured_output(AgentType)\n",
    "\n",
    "    response = chain.invoke({'input_text' : state['input_text']})\n",
    "\n",
    "    return {**state, 'agent_action' : response.agent_name}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "cbd2b2ed-8e99-4d03-8a38-d809476db216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_action': 'skill_analyzer', 'input_text': 'what is my weakness'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "result = router({'input_text' : \"what is my weakness\"})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f8453-d4ae-4122-abcd-c19768a0427b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5a892ad8-479d-4a4e-a22e-e8396e86e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Node that loads the user profile from the database and updates the graph state.\n",
    "    \"\"\"\n",
    "    \n",
    "    profile_data = get_user_profile_from()\n",
    "\n",
    "    state[\"skills\"] = profile_data.get(\"skills\", [])\n",
    "    state[\"education\"] = profile_data.get(\"education\", [])\n",
    "    state[\"experience\"] = profile_data.get(\"experience\", [])\n",
    "    state[\"projects\"] = profile_data.get(\"projects\", [])\n",
    "    state[\"certifications\"] = profile_data.get(\"certifications\", [])\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "99cad237-7705-430a-895b-50609048fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_action': 'skill_analyzer',\n",
      " 'certifications': [{'name': 'Google Advanced Data Analytics',\n",
      "                     'organization': 'Google'},\n",
      "                    {'name': 'IBM Data Science Professional Certificate',\n",
      "                     'organization': 'IBM'},\n",
      "                    {'name': 'IBM RAG and Agentic AI: Build Next-Gen AI '\n",
      "                             'Systems',\n",
      "                     'organization': 'IBM'},\n",
      "                    {'name': 'Deep Learning', 'organization': 'DeepLearningAI'},\n",
      "                    {'name': 'Machine Learning',\n",
      "                     'organization': 'DeepLearningAI'},\n",
      "                    {'name': 'Mathematics for Machine Learning Specialization',\n",
      "                     'organization': 'Imperial College London'},\n",
      "                    {'name': 'Mathematics for Machine Learning and Data '\n",
      "                             'Science',\n",
      "                     'organization': 'DeepLearning.AI'},\n",
      "                    {'name': 'Python for Everybody Specialization',\n",
      "                     'organization': 'University of Michigan'}],\n",
      " 'education': [{'cgpa': '8.82',\n",
      "                'degree': 'Bachelor of Computer Applications',\n",
      "                'end_date': 'June 2025',\n",
      "                'start_date': 'August 2022',\n",
      "                'university': 'Bangalore University'}],\n",
      " 'experience': [{'company': '',\n",
      "                 'description': '',\n",
      "                 'employment_type': '',\n",
      "                 'end_date': '',\n",
      "                 'location': '',\n",
      "                 'start_date': '',\n",
      "                 'title': ''}],\n",
      " 'input_text': 'what is my weakness',\n",
      " 'projects': [{'description': 'Developed AI web app detecting biases (race, '\n",
      "                              'gender, profession, religion) with '\n",
      "                              'Bidirectional LSTM with Self Attention, '\n",
      "                              'achieving ~98% accuracy via TensorFlow. Created '\n",
      "                              'Flask interface with Plotly for real-time '\n",
      "                              'visualization of bias probabilities and '\n",
      "                              'attention weights. '\n",
      "                              'https://github.com/sheb1lmsp/BiasBusterAI',\n",
      "               'end_date': 'October 2025',\n",
      "               'name': 'BiasBusterAI: Text Bias Detection System',\n",
      "               'start_date': 'October 2025'},\n",
      "              {'description': 'Developed a smart attendance management system '\n",
      "                              'using facial recognition to automate classroom '\n",
      "                              'attendance tracking. Leveraged PyTorch, MTCNN, '\n",
      "                              'and InceptionResNetV1 to build and train '\n",
      "                              'machine learning models for accurate face '\n",
      "                              'detection and recognition. Integrated the ML '\n",
      "                              'pipeline with a Django web application, '\n",
      "                              'featuring role-based dashboards for admins, '\n",
      "                              'teachers, and students. Enabled efficient '\n",
      "                              'attendance marking via group photos, '\n",
      "                              'streamlining academic workflows. '\n",
      "                              'https://github.com/sheb1lmsp/smart_attend',\n",
      "               'name': 'SmartAttend: An Automated Attendance Management System',\n",
      "               'start_date': 'August 2025'}],\n",
      " 'skills': ['Agentic AI',\n",
      "            'Retrieval Augmented Generation (RAG)',\n",
      "            'Large Language Models (LLMs)',\n",
      "            'LangChain',\n",
      "            'Django',\n",
      "            'LSTM',\n",
      "            'Flask',\n",
      "            'Transformers',\n",
      "            'RNN',\n",
      "            'TensorFlow',\n",
      "            'Supervised Learning',\n",
      "            'Unsupervised Learning',\n",
      "            'Pytorch',\n",
      "            'CNN',\n",
      "            'DBMS',\n",
      "            'DSA',\n",
      "            'Statistics',\n",
      "            'SQL',\n",
      "            'AI',\n",
      "            'Linear Algebra',\n",
      "            'Calculus',\n",
      "            'PCA',\n",
      "            'Python',\n",
      "            'Seaborn',\n",
      "            'Pandas',\n",
      "            'Numpy',\n",
      "            'Matplotlib',\n",
      "            'Scikit-learn',\n",
      "            'Data Analytics',\n",
      "            'Data Science',\n",
      "            'Machine Learning',\n",
      "            'Jupyter Notebook',\n",
      "            'Git']}\n"
     ]
    }
   ],
   "source": [
    "result = get_user_profile(result)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbab772-7f91-4ac0-9081-4179fe2c3173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "48b5d5b1-23cf-4ff9-8e6e-5ab74f14a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Suggests relevant courses or certifications based on user's profile,\n",
    "    while avoiding those the user has already completed or mentioned.\n",
    "    \"\"\"\n",
    "\n",
    "    user_skills = state.get(\"skills\", \"None\")\n",
    "    education = state.get(\"education\", \"None\")\n",
    "    projects = state.get(\"projects\", \"None\")\n",
    "    certifications = state.get(\"certifications\", \"None\")\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "\n",
    "    course_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the CourseRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your goal is to suggest highly relevant 'online courses or certifications'\n",
    "            from popular learning platforms (Coursera, Udemy, edX, Google, LinkedIn Learning, etc.)\n",
    "            that can help the user grow in their desired career direction.\n",
    "\n",
    "            âš ï¸ IMPORTANT RULES:\n",
    "            - DO NOT recommend any course, topic, or certification the user already has or mentioned.\n",
    "            - DO NOT suggest duplicates of known certifications.\n",
    "            - Focus on 'next-step' or 'complementary learning' opportunities.\n",
    "            - Recommend a maximum of 3â€“5 courses.\n",
    "            - For each course: include its platform and a one-line reason why it's relevant.\n",
    "            - Output must be 'plain text' (no JSON, no markdown).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or goal:\n",
    "            {user_query}\n",
    "\n",
    "            User profile details:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Projects: {projects}\n",
    "            - Completed Certifications: {certifications}\n",
    "\n",
    "            Return 3â€“5 courses the user has 'not yet done' that could strengthen or extend their abilities.\n",
    "\n",
    "            Format strictly like this:\n",
    "            1. [Course Name] â€” [Platform]\n",
    "               Why: [One-line reason]\n",
    "            2. [Course Name] â€” [Platform]\n",
    "               Why: [One-line reason]\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = course_prompt | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    state[\"final_output\"] = state[\"response\"]\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b20fe632-323f-4a5f-83ac-bb480d9e435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Machine Learning Engineering for Production (MLOps) â€” DeepLearning.AI (Coursera)\n",
      "   Why: This course will equip you with the skills to deploy, monitor, and maintain your advanced ML models in real-world production environments.\n",
      "2. Reinforcement Learning Specialization â€” University of Alberta (Coursera)\n",
      "   Why: Expand your AI expertise by delving into a new paradigm of machine learning focused on decision-making and optimal control in dynamic environments.\n",
      "3. Google Cloud Professional Machine Learning Engineer Professional Certificate â€” Google (Coursera)\n",
      "   Why: Gain hands-on experience and certification in designing, building, and deploying ML solutions on a leading cloud platform.\n",
      "4. Data Engineering with Google Cloud Professional Certificate â€” Google (Coursera)\n",
      "   Why: Strengthen your ability to build and manage robust data pipelines and infrastructure, essential for supporting large-scale machine learning projects.\n"
     ]
    }
   ],
   "source": [
    "result = course_recommender(result)\n",
    "print(result['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10a4f8-9621-4bcb-93e7-9ba930a2cd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9b359398-27e9-46ba-9f55-3a3316f82a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Suggests creative and technically relevant project ideas for the user,\n",
    "    avoiding overlap with existing projects.\n",
    "    \"\"\"\n",
    "\n",
    "    user_skills = \", \".join(state.get(\"skills\", \"None\"))\n",
    "    education = state.get(\"education\", \"None\")\n",
    "    experience = state.get(\"experience\", \"None\")\n",
    "    projects = state.get(\"projects\", \"None\")\n",
    "    certifications = state.get(\"certifications\", \"None\")\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "\n",
    "    project_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ProjectRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Suggest 'unique, high-impact project ideas' tailored to the userâ€™s skills, experience, and goals.\n",
    "            - The projects should help the user 'build portfolio depth' and 'improve employability'.\n",
    "\n",
    "            âš™ï¸ Rules:\n",
    "            - DO NOT suggest projects that are too similar to the userâ€™s existing ones.\n",
    "            - Suggest 3â€“5 'new and creative' project ideas.\n",
    "            - Include a one-line reason why each project is valuable.\n",
    "            - Prefer ideas that are relevant to the userâ€™s current skills but slightly challenging to help them grow.\n",
    "            - Avoid trivial projects (e.g., â€œTo-Do Appâ€, â€œCalculator Appâ€).\n",
    "            - Output must be 'plain text only' (no markdown, no JSON).\n",
    "\n",
    "            ðŸŽ¯ Example areas:\n",
    "            - If the user has AI/ML skills â†’ suggest applied ML, NLP, GenAI, or automation projects.\n",
    "            - If the user is from software/dev background â†’ suggest scalable systems or automation tools.\n",
    "            - If the user is from data analytics â†’ suggest visualization dashboards or predictive models.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or career goal:\n",
    "            {user_query}\n",
    "\n",
    "            User profile:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Certifications: {certifications}\n",
    "            - Existing Projects: {projects}\n",
    "\n",
    "            Recommend 3â€“5 unique project ideas the user can build next.\n",
    "            Each idea should include:\n",
    "            1. Project Name â€” short and creative\n",
    "            2. One-sentence description\n",
    "            3. Why it's valuable\n",
    "\n",
    "            Output format:\n",
    "            1. [Project Name]\n",
    "               Description: ...\n",
    "               Why: ...\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = project_prompt | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\" : certifications,\n",
    "    })\n",
    "\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    state[\"final_output\"] = state[\"response\"]\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c02030dd-890b-406d-834a-ac38b0a688df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DocuAgent: Intelligent Knowledge Retrieval System\n",
      "   Description: Develop an AI agent that uses Retrieval Augmented Generation (RAG) and LangChain to provide accurate, context-aware answers from a large, domain-specific document corpus, enhancing information accessibility and reducing hallucination.\n",
      "   Why: Directly applies advanced LLM techniques (RAG, Agentic AI, LangChain) to a practical problem, demonstrating ability to build robust, verifiable AI systems.\n",
      "\n",
      "2. CodeCraft AI: Contextual Code Generation Assistant\n",
      "   Description: Build an AI assistant that generates code snippets or full functions based on natural language prompts, leveraging fine-tuned Large Language Models and a retrieval mechanism to incorporate best practices or existing code patterns.\n",
      "   Why: Showcases advanced generative AI application, understanding of code semantics, and ability to integrate LLMs for practical developer tools.\n",
      "\n",
      "3. SentinelStream: Real-time Anomaly Detection System\n",
      "   Description: Develop a system that detects unusual patterns or anomalies in streaming sensor data or financial time series using a combination of deep learning models (e.g., LSTMs, Autoencoders) and statistical methods, providing real-time alerts.\n",
      "   Why: Applies deep learning to a critical real-world problem (anomaly detection/forecasting), demonstrating ability to handle sequential data and build robust monitoring systems.\n",
      "\n",
      "4. MultiModal Insight Engine\n",
      "   Description: Create an application that processes and integrates information from both images and text documents (e.g., product reviews with images, medical reports with scans) to provide comprehensive insights, utilizing CNNs for image analysis and LLMs for text understanding and cross-modal reasoning.\n",
      "   Why: Showcases advanced integration of different deep learning architectures (CNNs, LLMs) and ability to handle complex multi-modal data for richer insights.\n"
     ]
    }
   ],
   "source": [
    "result = project_recommender(result)\n",
    "print(result['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6718444-66d3-4589-8de2-5323d95dad77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a61b3c24-9d0c-4916-9071-d3333d499839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningPath(BaseModel):\n",
    "    target_role: str = Field(description=\"The goal or role the user wants to prepare for\")\n",
    "    required_skills: List[str] = Field(description=\"Skills or topics the user needs to learn next\")\n",
    "    roadmap_steps: List[str] = Field(description=\"Chronological learning steps\")\n",
    "    recommended_resources: List[str] = Field(description=\"Optional recommended learning resources\")\n",
    "    summary: str = Field(description=\"A short summary of the learning plan\")\n",
    "\n",
    "def learning_path_advisor(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Node that generates a step-by-step learning roadmap for the user's desired goal.\n",
    "    Uses known skills and background to avoid redundancy.\n",
    "    \"\"\"\n",
    "\n",
    "    user_input = state.get(\"input_text\", \"\")\n",
    "    known_skills = \" \".join(state.get(\"skills\", \"None\"))\n",
    "    certifications = state.get(\"certifications\", \"None\")\n",
    "    education = state.get(\"education\", \"None\")\n",
    "    experience = state.get(\"experience\", \"None\")\n",
    "    projects = state.get(\"projects\", \"None\")\n",
    "\n",
    "    learning_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the LearningPath Advisor for CareerGraph AI.\n",
    "            You specialize in creating personalized, practical, and efficient learning roadmaps \n",
    "            based on the userâ€™s profile, skills, and goals.\n",
    "\n",
    "            Guidelines:\n",
    "            - Recommend skills and learning steps relevant to the user's career goal.\n",
    "            - DO NOT include skills, courses, or certifications the user already has.\n",
    "            - Keep the roadmap structured, progressive, and goal-oriented.\n",
    "            - Assume the user prefers real-world applicability (projects, portfolios, and measurable milestones).\n",
    "            - If no clear goal is stated, infer one from their background and interests.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {user_input}\n",
    "\n",
    "            Known Skills: {known_skills}\n",
    "            Certifications: {certifications}\n",
    "            Education: {education}\n",
    "            Experience: {experience}\n",
    "            Projects: {projects}\n",
    "\n",
    "            Provide:\n",
    "            - target_role\n",
    "            - required_skills (excluding known ones)\n",
    "            - roadmap_steps (chronological)\n",
    "            - recommended_resources (optional)\n",
    "            - summary\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = learning_prompt | llm.with_structured_output(LearningPath)\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"known_skills\": known_skills,\n",
    "        \"certifications\": certifications,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "    })\n",
    "\n",
    "    formatted_output = (\n",
    "        f\"ðŸŽ¯ **Target Role:** {response.target_role}\\n\\n\"\n",
    "        f\"ðŸ§© **Required Skills:** {', '.join(response.required_skills)}\\n\\n\"\n",
    "        f\"ðŸªœ **Learning Roadmap:**\\n\" + \"\\n\".join([f\"- {step}\" for step in response.roadmap_steps]) + \"\\n\\n\"\n",
    "        f\"ðŸ“˜ **Recommended Resources:**\\n\" + \"\\n\".join([f\"- {r}\" for r in response.recommended_resources]) + \"\\n\\n\"\n",
    "        f\"ðŸ“ **Summary:** {response.summary}\"\n",
    "    )\n",
    "\n",
    "    state[\"response\"] = formatted_output\n",
    "    state[\"final_output\"] = formatted_output\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a59aac7d-e2fc-42a8-b98d-c07fd4ce05a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ **Target Role:** AI Engineer (LLM Focus)\n",
      "\n",
      "ðŸ§© **Required Skills:** Advanced Prompt Engineering, LLM Fine-tuning (LoRA, QLoRA), Vector Database Implementation (Pinecone, Weaviate, Milvus), MLOps for LLMs (Docker, Kubernetes, Cloud ML Platforms like AWS Sagemaker/GCP Vertex AI), Reinforcement Learning from Human Feedback (RLHF), LLM Evaluation and Benchmarking, System Design for Scalable LLM Applications, LLM Optimization Techniques (Quantization, Pruning)\n",
      "\n",
      "ðŸªœ **Learning Roadmap:**\n",
      "- Master Advanced Prompt Engineering: Learn and apply advanced techniques (e.g., Chain-of-Thought, Tree-of-Thought, Self-Consistency) to build sophisticated LLM interactions. Milestone: Develop a project demonstrating a multi-turn, context-aware LLM agent using advanced prompting.\n",
      "- Deep Dive into LLM Fine-tuning: Understand and implement parameter-efficient fine-tuning (PEFT) methods like LoRA and QLoRA on open-source LLMs. Milestone: Fine-tune a specialized LLM for a specific domain task and evaluate its performance.\n",
      "- Implement Advanced RAG with Vector Databases: Explore and integrate dedicated vector databases (e.g., Pinecone, Weaviate) into RAG pipelines for highly efficient and scalable information retrieval. Milestone: Build an RAG application leveraging a vector database for improved contextual understanding and retrieval accuracy.\n",
      "- Gain MLOps Expertise for LLMs: Learn to containerize LLM applications with Docker, orchestrate deployments with Kubernetes, and manage LLM lifecycles on cloud platforms (e.g., AWS SageMaker, GCP Vertex AI). Milestone: Deploy a production-ready LLM application as a scalable service using Docker, Kubernetes, and a cloud provider.\n",
      "- Explore Reinforcement Learning from Human Feedback (RLHF): Understand the principles and basic architecture of RLHF for aligning LLMs with human preferences and values. Milestone: Develop a conceptual design or a simplified proof-of-concept for an RLHF pipeline to improve LLM behavior.\n",
      "- Develop Comprehensive LLM Evaluation Strategies: Learn to establish robust evaluation metrics and benchmarking methodologies for assessing LLM performance, reliability, and safety beyond traditional metrics. Milestone: Create an evaluation framework and conduct a thorough benchmark for an LLM application, identifying areas for improvement.\n",
      "- Master System Design for LLM Applications: Learn to architect resilient, scalable, and cost-effective end-to-end LLM systems, considering data pipelines, inference, and integration. Milestone: Design a detailed system architecture for a complex, real-world LLM application, justifying technology choices.\n",
      "- Implement LLM Optimization Techniques: Apply techniques such as quantization and pruning to reduce model size and improve inference speed for efficient deployment. Milestone: Optimize a trained LLM using quantization and demonstrate its impact on resource utilization and latency.\n",
      "\n",
      "ðŸ“˜ **Recommended Resources:**\n",
      "- Generative AI with Transformers in Google Cloud specialization on Coursera\n",
      "- Practical MLOps by Noah Gift and Alfredo Deza\n",
      "- Documentation and tutorials for Hugging Face Transformers, PEFT, and TRL libraries\n",
      "- Official documentation for Docker, Kubernetes, Pinecone, Weaviate, AWS SageMaker, and GCP Vertex AI\n",
      "- Research papers and blogs on recent advancements in LLM fine-tuning, RLHF, and evaluation\n",
      "- Online communities and forums for LLM development and MLOps practices\n",
      "\n",
      "ðŸ“ **Summary:** This learning path is designed for a highly skilled individual with a strong foundation in AI/ML/LLMs to specialize as an AI Engineer focusing on Large Language Models. It emphasizes practical application, advanced techniques, MLOps for deployment, and ethical considerations, preparing the user to build and deploy sophisticated LLM-powered systems.\n"
     ]
    }
   ],
   "source": [
    "result = learning_path_advisor(result)\n",
    "print(result['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f3d26-10fc-4d9e-8029-3eaefe0318eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8300d766-a206-42af-9b55-530e6d3265c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_analyzer(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Analyzes the user's skills, projects, and experience, and returns \n",
    "    an unstructured natural-language summary of their strengths and upskilling recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are CareerGraph AIâ€™s Skill Analyzer Agent.\n",
    "            Your job:\n",
    "            - Analyze the user's current skills, experience, and projects.\n",
    "            - Identify their strongest skills and areas of expertise.\n",
    "            - Point out gaps or weaknesses.\n",
    "            - Suggest a few new skills, courses, or technologies to improve their profile.\n",
    "            - Be concise and specific, using bullet points or a short paragraph.\n",
    "\n",
    "            Output format:\n",
    "            - Core Strengths:\n",
    "            - Missing / Weak Skills:\n",
    "            - Recommended Upskilling:\n",
    "            - Suggested Courses / Certifications:\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Current Skills: {skills}\n",
    "            Education: {education}\n",
    "            Experience: {experience}\n",
    "            Projects: {projects}\n",
    "            Certifications: {certifications}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": state.get(\"input_text\", \"\"),\n",
    "        \"skills\": state.get(\"skills\", []),\n",
    "        \"education\": state.get(\"education\", []),\n",
    "        \"experience\": state.get(\"experience\", []),\n",
    "        \"projects\": state.get(\"projects\", []),\n",
    "        \"certifications\": state.get(\"certifications\", [])\n",
    "    })\n",
    "\n",
    "    state[\"response\"] = response.content\n",
    "    state[\"final_output\"] = response.content\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1e4aea6a-7753-411b-826d-84b573a2fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your impressive skills, projects, and certifications, you have a very strong foundation in AI, Machine Learning, Deep Learning, and web development. Your projects demonstrate practical application of advanced concepts like RAG, Agentic AI, LLMs, NLP, and Computer Vision.\n",
      "\n",
      "However, to address your query about weaknesses and further enhance your profile, here are some areas:\n",
      "\n",
      "*   **Core Strengths:**\n",
      "    *   **Deep Learning & NLP Expertise:** Strong grasp of LLMs, RAG, Agentic AI, Transformers, LSTM, CNN, RNN, and practical application in projects (BiasBusterAI, SmartAttend).\n",
      "    *   **Solid ML & Data Science Foundation:** Comprehensive skills in supervised/unsupervised learning, Python data stack (Pandas, Numpy, Scikit-learn), statistics, and mathematical foundations.\n",
      "    *   **Web Integration:** Ability to integrate ML models into functional web applications using Flask and Django.\n",
      "    *   **Robust Certifications:** Validated knowledge across core ML, DL, Data Science, and advanced AI topics from reputable organizations.\n",
      "\n",
      "*   **Missing / Weak Skills:**\n",
      "    *   **MLOps & Production Deployment:** While you build web apps, explicit skills in deploying, monitoring, and maintaining ML models in production environments (e.g., Docker, Kubernetes, CI/CD pipelines, model versioning).\n",
      "    *   **Cloud Platform Expertise:** Specific experience with major cloud providers (AWS, Azure, GCP) for MLOps, data storage, and compute resources.\n",
      "    *   **Big Data Technologies:** Skills in distributed data processing frameworks (e.g., Apache Spark, Hadoop) for handling large-scale datasets, which are common in industry.\n",
      "    *   **Advanced Data Engineering:** Beyond basic DBMS/SQL, knowledge of data warehousing, ETL pipelines, and stream processing.\n",
      "    *   **System Design for ML:** Designing scalable, fault-tolerant, and performant ML systems from an architectural perspective.\n",
      "\n",
      "*   **Recommended Upskilling:**\n",
      "    *   **MLOps Tools & Practices:** Learn about containerization (Docker), orchestration (Kubernetes), and CI/CD for ML.\n",
      "    *   **Cloud ML Services:** Gain hands-on experience with services like AWS Sagemaker, Google Cloud AI Platform, or Azure Machine Learning.\n",
      "    *   **Distributed Computing:** Explore Apache Spark for processing large datasets.\n",
      "    *   **Data Pipeline Orchestration:** Look into tools like Apache Airflow for managing complex data workflows.\n",
      "\n",
      "*   **Suggested Courses / Certifications:**\n",
      "    *   **Machine Learning Engineering for Production (MLOps) Specialization** by DeepLearning.AI on Coursera.\n",
      "    *   **AWS Certified Machine Learning â€“ Specialty** or **Azure AI Engineer Associate** certification.\n",
      "    *   **Databricks Certified Associate Developer for Apache Spark**.\n",
      "    *   **Google Cloud Professional Machine Learning Engineer** certification.\n"
     ]
    }
   ],
   "source": [
    "result = skill_analyzer(result)\n",
    "print(result['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c363ca-fa99-4a4f-8f8f-e0395d9f9988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f489a7d-3d4e-4595-acee-dea8e6cecfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892bff7-8665-4196-99bc-457e8b8f7959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6e0ab-a425-4f62-a4cd-df5de733b891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae27a37-2166-46c9-a1f7-8ff531c02a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e954c40a-5784-4a41-8cd3-560118073d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDescriptionModel(BaseModel):\n",
    "    is_job_description: bool = Field(description=\"True if the input contains a job description or job post.\")\n",
    "    job_title: str = Field(description=\"The job title or role name, if mentioned.\", default=\"\")\n",
    "    company: str = Field(description=\"The company name, if mentioned.\", default=\"\")\n",
    "    required_skills: list[str] = Field(description=\"List of technical or soft skills mentioned.\", default=[])\n",
    "    responsibilities: list[str] = Field(description=\"List of key responsibilities or tasks mentioned.\", default=[])\n",
    "    experience_level: str = Field(description=\"Experience level (e.g., Entry-level, Mid-level, Senior), if detectable.\", default=\"\")\n",
    "    summary: str = Field(description=\"2-line summary of what the role is about.\", default=\"\")\n",
    "\n",
    "def job_description_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Parses job descriptions from user input and stores structured details\n",
    "    in state['metadata']['job_description'].\n",
    "    \"\"\"\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "\n",
    "    jd_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the JobDescriptionParser Agent for CareerGraph AI.\n",
    "            Your job:\n",
    "            - Detect if the user provided a job description.\n",
    "            - If yes, extract structured details:\n",
    "              â€¢ job_title\n",
    "              â€¢ company\n",
    "              â€¢ required_skills\n",
    "              â€¢ responsibilities\n",
    "              â€¢ experience_level\n",
    "              â€¢ summary\n",
    "            - If not, set is_job_description=False.\n",
    "            - Be factual and concise.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"User input:\\n{user_query}\")\n",
    "    ])\n",
    "\n",
    "    chain = jd_prompt | llm.with_structured_output(JobDescriptionModel)\n",
    "    response = chain.invoke({\"user_query\": user_query})\n",
    "\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "\n",
    "    state[\"metadata\"][\"job_description\"] = response.model_dump()\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "193cca7f-f9e0-4c8a-bc05-89906578f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_job_description': True,\n",
       " 'job_title': 'Data Scientist',\n",
       " 'company': 'Tesco',\n",
       " 'required_skills': ['Machine Learning',\n",
       "  'Data Mining',\n",
       "  'Advanced Algorithms',\n",
       "  'Statistics',\n",
       "  'Python',\n",
       "  'Predictive Modelling',\n",
       "  'Operational Research',\n",
       "  'Deep Learning',\n",
       "  'Time Series Modelling',\n",
       "  'Hadoop',\n",
       "  'Spark',\n",
       "  'Mathematical Modeling',\n",
       "  'Communication',\n",
       "  'Problem Solving'],\n",
       " 'responsibilities': ['Model complex business problems and deploy data products at scale',\n",
       "  'Understand difficult business problems and prototype solutions with minimal support',\n",
       "  'Apply, modify and design algorithms and mathematical models to solve business problems on top of big data architectures (Hadoop, Spark)',\n",
       "  'Validate, document and present the modeling process and performances',\n",
       "  'Communicate complex solutions in a clear, understandable way to non-experts',\n",
       "  'Promote data science across Tesco and promote Tesco across the external Data Science community'],\n",
       " 'experience_level': 'Senior',\n",
       " 'summary': 'This Senior Data Scientist role at Tesco involves applying advanced machine learning, statistical modeling, and big data technologies (Hadoop, Spark) to solve complex business problems across various domains. The ideal candidate will have strong programming skills in Python, a solid understanding of mathematical principles, and the ability to communicate complex solutions effectively.'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = job_description_parser(result)\n",
    "result['metadata']['job_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163881d1-bb80-49f2-b478-82fe4cc78be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c01d32ac-0645-4b41-82e3-47060f2e4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "from docx import Document\n",
    "\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"Extract text from PDF using PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_text_from_docx(file_path: str) -> str:\n",
    "    \"\"\"Extract text from DOCX using python-docx.\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_resume_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Unified loader that detects file type (.pdf or .docx)\n",
    "    and extracts clean text for LLM input.\n",
    "    \"\"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        return extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload a PDF or DOCX resume.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "9f837740-d4a4-4449-92bd-c7a44e81d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeModel(BaseModel):\n",
    "    name: str = Field(description=\"Full name of the candidate, if available\", default=\"\")\n",
    "    email: str = Field(description=\"Email address of the candidate\", default=\"\")\n",
    "    phone: str = Field(description=\"Phone number, if mentioned\", default=\"\")\n",
    "    summary: str = Field(description=\"Brief 2-3 line professional summary from the resume\", default=\"\")\n",
    "    skills: List[str] = Field(description=\"List of technical or soft skills\", default=[])\n",
    "    education: List[str] = Field(description=\"List of educational qualifications and universities\", default=[])\n",
    "    experience: List[str] = Field(description=\"List of work experience entries or job roles\", default=[])\n",
    "    certifications: List[str] = Field(description=\"List of certifications or achievements\", default=[])\n",
    "    projects: List[str] = Field(description=\"List of project titles or descriptions\", default=[])\n",
    "    total_experience_years: float = Field(description=\"Approximate total years of experience\", default=0.0)\n",
    "\n",
    "def resume_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Parses resume text from user input and stores structured details\n",
    "    inside state['metadata']['resume_data'].\n",
    "    Does NOT overwrite or modify top-level state fields.\n",
    "    \"\"\"\n",
    "\n",
    "    resume_text = state.get('resume_text', \"None\")\n",
    "\n",
    "    resume_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ResumeParser Agent for CareerGraph AI.\n",
    "            Your job:\n",
    "            - Analyze the provided text (which may come from a resume).\n",
    "            - Extract the following structured fields:\n",
    "              â€¢ name\n",
    "              â€¢ email\n",
    "              â€¢ phone\n",
    "              â€¢ summary\n",
    "              â€¢ skills\n",
    "              â€¢ education\n",
    "              â€¢ experience\n",
    "              â€¢ certifications\n",
    "              â€¢ projects\n",
    "              â€¢ total_experience_years (approx)\n",
    "            - If no resume details are detected, leave fields empty.\n",
    "            - Return data in structured JSON matching the ResumeModel schema.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"Resume text:\\n{resume_text}\")\n",
    "    ])\n",
    "\n",
    "    chain = resume_prompt | llm.with_structured_output(ResumeModel)\n",
    "    response = chain.invoke({\"resume_text\": resume_text})\n",
    "\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "    state[\"metadata\"][\"resume_data\"] = response.model_dump()\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "03a334a8-63c8-4903-9111-b34d5e59dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../../../Desktop/CV/Mohammed_Shebil_Resume.pdf\"\n",
    "\n",
    "result = resume_parser({'resume_text' : extract_resume_text(file_path)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b1be608c-48f8-4dc5-a53d-f534c94f2399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resume_data': {'name': 'Mohammed Shebil P',\n",
       "  'email': 'shebil.mohammed.p@gmail.com',\n",
       "  'phone': '+91 86062 19789',\n",
       "  'summary': 'Recent graduate with strong skills in Machine Learning, AI, and data analytics, seeking opportunities to apply technical expertise in real-world projects.',\n",
       "  'skills': ['Supervised Learning',\n",
       "   'Unsupervised Learning',\n",
       "   'NLP',\n",
       "   'Computer Vision',\n",
       "   'CNN',\n",
       "   'RNN',\n",
       "   'Transformers',\n",
       "   'LLMs',\n",
       "   'Generative AI',\n",
       "   'Python (Advanced)',\n",
       "   'SQL (Intermediate)',\n",
       "   'PyTorch',\n",
       "   'TensorFlow',\n",
       "   'Keras',\n",
       "   'Scikit-learn',\n",
       "   'XGBoost',\n",
       "   'Pandas',\n",
       "   'NumPy',\n",
       "   'PySpark',\n",
       "   'Django',\n",
       "   'Flask',\n",
       "   'SQLite',\n",
       "   'Git',\n",
       "   'Google Cloud Platform (Vertex AI, BigQuery)',\n",
       "   'Seaborn',\n",
       "   'Matplotlib',\n",
       "   'Tableau',\n",
       "   'Power BI'],\n",
       "  'education': ['Bachelor of Computer Applications - Bangalore University, Bengaluru (August 2022 - June 2025)'],\n",
       "  'experience': [],\n",
       "  'certifications': ['Deep Learning Specialization, DeepLearning.AI, 2025',\n",
       "   'Machine Learning Specialization, DeepLearning.AI, 2025',\n",
       "   'Data Science Professional Certificate, IBM, 2025',\n",
       "   'Google Advanced Data Analytics, Google, 2025',\n",
       "   'Mathematics for Machine Learning and Data Science, DeepLearning.AI, 2025'],\n",
       "  'projects': ['Bias Buster AI: Text Bias Detection System - Independent Project',\n",
       "   'Smart Attend: An Automated Attendance Management System - Academic Project, Bangalore University'],\n",
       "  'total_experience_years': 0.0}}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998d2d3-00ea-4183-b57b-cf3adb804e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "5ae5e331-bb99-4405-ae96-375aefab2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_coach(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI - Interview Coach Agent\n",
    "    Provides personalized interview guidance based on job description, resume, or user data.\n",
    "    \"\"\"\n",
    "    job_description = None\n",
    "    resume_data = None\n",
    "\n",
    "    if state.get(\"metadata\"):\n",
    "        job_description = state[\"metadata\"].get(\"job_description\")\n",
    "        resume_data = state[\"metadata\"].get(\"resume_data\")\n",
    "\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "\n",
    "    context_parts = []\n",
    "\n",
    "    if job_description and job_description.get(\"is_job_description\"):\n",
    "        context_parts.append(\n",
    "            f\"Job Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"Summary: {job_description.get('summary', '')}\\n\"\n",
    "        )\n",
    "\n",
    "    if resume_data:\n",
    "        context_parts.append(\n",
    "            \"Candidate Resume:\\n\"\n",
    "            f\"Name: {resume_data.get('name', 'N/A')}\\n\"\n",
    "            f\"Skills: {', '.join(resume_data.get('skills', []))}\\n\"\n",
    "            f\"Experience: {', '.join(resume_data.get('experience', []))}\\n\"\n",
    "            f\"Projects: {', '.join(resume_data.get('projects', []))}\\n\"\n",
    "            f\"Education: {', '.join(resume_data.get('education', []))}\\n\"\n",
    "        )\n",
    "\n",
    "    if not context_parts:\n",
    "        context_parts.append(\n",
    "            \"User profile data:\\n\"\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp['title'] + ' at ' + exp['company'] for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu['degree'] + ' at ' + edu['university'] for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p['name'] for p in projects])}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the Interview Coach Agent for CareerGraph AI.\n",
    "            Your goal:\n",
    "            - Prepare the user for their upcoming job interview.\n",
    "            - Analyze the given job description, resume, or available data.\n",
    "            - Identify the key technical and behavioral areas the user should prepare for.\n",
    "            - Suggest possible interview questions and tips for answering them effectively.\n",
    "            - If the role or company is mentioned, tailor your advice to that.\n",
    "\n",
    "            Output structure:\n",
    "            1. Role Context (1â€“2 lines)\n",
    "            2. Key Focus Areas\n",
    "            3. Likely Technical Questions\n",
    "            4. Behavioral Questions\n",
    "            5. Preparation Tips\n",
    "            6. Bonus Recommendations (optional)\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Context Information:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": state.get(\"input_text\", \"\"),\n",
    "        \"combined_context\": combined_context,\n",
    "    })\n",
    "\n",
    "    state[\"response\"] = response.content\n",
    "    state[\"final_output\"] = response.content\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c398fe9-e075-4607-a4b4-fd0cf18beaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6eb9d904-d1d0-4cd9-a57d-8896ed5916d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_builder(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI - Resume Builder Agent (ATS + HR Selection Model)\n",
    "\n",
    "    Phase 1: ATS Engine creates 5 optimized resume variations for the target role.\n",
    "    Phase 2: HR Reviewer selects the best one based on impact, clarity, and relevance.\n",
    "    \"\"\"\n",
    "    job_description = None\n",
    "    resume_data = None\n",
    "\n",
    "    if state.get(\"metadata\"):\n",
    "        job_description = state[\"metadata\"].get(\"job_description\")\n",
    "        resume_data = state[\"metadata\"].get(\"resume_data\")\n",
    "\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "\n",
    "    context_parts = []\n",
    "\n",
    "    if job_description and job_description.get(\"is_job_description\"):\n",
    "        context_parts.append(\n",
    "            f\"Job Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"Summary: {job_description.get('summary', '')}\\n\"\n",
    "        )\n",
    "\n",
    "    if resume_data:\n",
    "        context_parts.append(\n",
    "            \"Existing Resume:\\n\"\n",
    "            f\"Name: {resume_data.get('name', 'N/A')}\\n\"\n",
    "            f\"Skills: {', '.join(resume_data.get('skills', []))}\\n\"\n",
    "            f\"Experience: {', '.join(resume_data.get('experience', []))}\\n\"\n",
    "            f\"Projects: {', '.join(resume_data.get('projects', []))}\\n\"\n",
    "            f\"Education: {', '.join(resume_data.get('education', []))}\\n\"\n",
    "        )\n",
    "\n",
    "    if not context_parts:\n",
    "        context_parts.append(\n",
    "            \"User profile data:\\n\"\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp['title'] + ' at ' + exp['company'] for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu['degree'] + ' at ' + edu['university'] for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p['name'] for p in projects])}\\n\"\n",
    "            f\"Certifications: {', '.join([c['name'] for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the Resume Builder Agent for CareerGraph AI.\n",
    "            Think in two roles:\n",
    "\n",
    "            Phase 1 â€” ATS Engine:\n",
    "            â€¢ Imagine you are an Applicant Tracking System (ATS) analyzing a candidate profile and job description.\n",
    "            â€¢ Generate FIVE unique, highly ATS-friendly resumes.\n",
    "            â€¢ Each resume should follow this consistent format:\n",
    "                ======================\n",
    "                [FULL NAME]\n",
    "                [PROFESSIONAL SUMMARY]\n",
    "                [SKILLS]\n",
    "                [EXPERIENCE]\n",
    "                [PROJECTS]\n",
    "                [EDUCATION]\n",
    "                [CERTIFICATIONS] (optional)\n",
    "                ======================\n",
    "            â€¢ Focus on keyword density, clear headers, measurable results, and job relevance.\n",
    "            â€¢ Each resume should slightly vary in focus or phrasing â€” one more technical, one more business-focused, one more concise, etc.\n",
    "\n",
    "            Phase 2 â€” HR Reviewer:\n",
    "            â€¢ Now imagine you are a human recruiter reviewing those 5 resumes.\n",
    "            â€¢ Choose the ONE resume that would most likely get shortlisted for an interview.\n",
    "            â€¢ Explain briefly (2â€“3 lines) why this version stands out.\n",
    "            â€¢ Output only the chosen resume and the short explanation at the end.\n",
    "\n",
    "            Output format:\n",
    "            ======================\n",
    "            [FINAL SELECTED RESUME TEXT]\n",
    "            ======================\n",
    "            HR Comment: <why it was chosen>\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Context Information:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": state.get(\"input_text\", \"\"),\n",
    "        \"combined_context\": combined_context,\n",
    "    })\n",
    "\n",
    "    state[\"response\"] = response.content\n",
    "    state[\"final_output\"] = response.content\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7243c0-5978-4e20-b039-39c0cceb8e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
