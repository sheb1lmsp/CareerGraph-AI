{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba5ef31-5a41-4cfc-908b-e64b32569843",
   "metadata": {},
   "source": [
    "# üöÄ CareerGraph AI ‚Äî Multi-Agent System using LangGraph & LangChain\n",
    "\n",
    "**CareerGraph AI** is an intelligent, LLM-powered multi-agent framework designed to deliver personalized career guidance.  \n",
    "It integrates multiple specialized agents (e.g., `resume_builder`, `interview_coach`, `skill_analyzer`, etc.) within a LangGraph-based orchestration pipeline.\n",
    "\n",
    "### üîç Key Features\n",
    "- **Multi-Agent Workflow:** Dynamically routes user queries to specialized agents via a central `router`.\n",
    "- **Context-Aware Conversation:** Maintains conversational memory with summarization for long-term context.\n",
    "- **Dynamic Exit Management:** Gracefully handles user exits using a conversation-aware `exit_chain`.\n",
    "- **Agent Specialization:**\n",
    "  - üß≠ `learning_path_advisor` ‚Äî Personalized learning recommendations  \n",
    "  - üß† `skill_analyzer` ‚Äî Analyzes and improves skill portfolios  \n",
    "  - üíº `resume_builder` ‚Äî Generates ATS-friendly resumes  \n",
    "  - üéØ `interview_coach` ‚Äî Provides tailored interview preparation  \n",
    "  - üéì `course_recommender` & `project_recommender` ‚Äî Suggests career-enhancing projects and courses  \n",
    "- **Graph-Based Architecture:** Built using `LangGraph` with conditional routing and sequential agent execution.\n",
    "\n",
    "### ‚öôÔ∏è Components Overview\n",
    "1. **StateGraph Setup:** Defines all nodes and transitions between agents.  \n",
    "2. **Agent Nodes:** Each agent operates as a modular function processing the shared `state`.  \n",
    "3. **Conversation Loop:** Interactive CLI loop that handles user input, memory, and routing.  \n",
    "\n",
    "---\n",
    "\n",
    "> üí° *This notebook serves as a complete, self-contained prototype of the CareerGraph AI system ‚Äî combining LangGraph, LangChain, and LLM reasoning to simulate an adaptive career assistant.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a61a1-1574-4216-921d-533f58f83c65",
   "metadata": {},
   "source": [
    "### `get_user_profile_from()` ‚Äî Dummy Profile Generator\n",
    "\n",
    "This function creates a **realistic, structured test user profile** for CareerGraph AI.\n",
    "\n",
    "---\n",
    "\n",
    "#### Purpose\n",
    "Used for:\n",
    "- Development and testing when LinkedIn or live profile fetching isn‚Äôt active.\n",
    "- Ensuring downstream agents (like `resume_builder`, `interview_coach`, etc.) can process valid structured input.\n",
    "\n",
    "---\n",
    "\n",
    "#### Data Included\n",
    "\n",
    "| Section | Description |\n",
    "|----------|-------------|\n",
    "| **Skills** | A wide range of AI, ML, and software development skills. |\n",
    "| **Certifications** | Popular industry credentials (Google, IBM, DeepLearning.AI, etc.). |\n",
    "| **Projects** | Realistic AI + web projects with GitHub links. |\n",
    "| **Education** | Undergraduate degree with CGPA and timeline. |\n",
    "| **Experience** | Empty template (acts as placeholder). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6246c30-a1d4-4746-ba9a-9d68d298191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile_from():\n",
    "    \"\"\"\n",
    "    Returns a structured dummy user profile for internal testing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing user data with the following keys:\n",
    "              - 'education'\n",
    "              - 'certifications'\n",
    "              - 'projects'\n",
    "              - 'skills'\n",
    "              - 'experience'\n",
    "    \"\"\"\n",
    "\n",
    "    # Skills\n",
    "    skills = [\n",
    "        'Agentic AI', 'Retrieval Augmented Generation (RAG)', 'Large Language Models (LLMs)',\n",
    "        'LangChain', 'Django', 'LSTM', 'Flask', 'Transformers', 'RNN', 'TensorFlow',\n",
    "        'Supervised Learning', 'Unsupervised Learning', 'Pytorch', 'CNN', 'DBMS', 'DSA',\n",
    "        'Statistics', 'SQL', 'AI', 'Linear Algebra', 'Calculus', 'PCA', 'Python',\n",
    "        'Seaborn', 'Pandas', 'Numpy', 'Matplotlib', 'Scikit-learn', 'Data Analytics',\n",
    "        'Data Science', 'Machine Learning', 'Jupyter Notebook', 'Git'\n",
    "    ]\n",
    "\n",
    "    # Certifications\n",
    "    certifications = [\n",
    "        {'name': 'Google Advanced Data Analytics', 'organization': 'Google'},\n",
    "        {'name': 'IBM Data Science Professional Certificate', 'organization': 'IBM'},\n",
    "        {'name': 'IBM RAG and Agentic AI: Build Next-Gen AI Systems', 'organization': 'IBM'},\n",
    "        {'name': 'Deep Learning', 'organization': 'DeepLearningAI'},\n",
    "        {'name': 'Machine Learning', 'organization': 'DeepLearningAI'},\n",
    "        {'name': 'Mathematics for Machine Learning Specialization', 'organization': 'Imperial College London'},\n",
    "        {'name': 'Mathematics for Machine Learning and Data Science', 'organization': 'DeepLearning.AI'},\n",
    "        {'name': 'Python for Everybody Specialization', 'organization': 'University of Michigan'}\n",
    "    ]\n",
    "\n",
    "    # Projects\n",
    "    projects = [\n",
    "        {\n",
    "            'name': 'BiasBusterAI: Text Bias Detection System',\n",
    "            'start_date': 'October 2025',\n",
    "            'end_date': 'October 2025',\n",
    "            'description': (\n",
    "                'Developed AI web app detecting biases (race, gender, profession, religion) '\n",
    "                'with Bidirectional LSTM + Self Attention, achieving ~98% accuracy via TensorFlow. '\n",
    "                'Created Flask interface with Plotly for real-time visualization of bias probabilities '\n",
    "                'and attention weights. https://github.com/sheb1lmsp/BiasBusterAI'\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            'name': 'SmartAttend: An Automated Attendance Management System',\n",
    "            'start_date': 'May 2025',\n",
    "            'end_date': 'August 2025',\n",
    "            'description': (\n",
    "                'Developed a smart attendance management system using facial recognition to automate '\n",
    "                'classroom attendance tracking. Leveraged PyTorch, MTCNN, and InceptionResNetV1 for '\n",
    "                'face detection and recognition. Integrated with a Django web application featuring '\n",
    "                'role-based dashboards. Streamlined attendance via group photo analysis. '\n",
    "                'https://github.com/sheb1lmsp/smart_attend'\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Education\n",
    "    education = [\n",
    "        {\n",
    "            'degree': 'Bachelor of Computer Applications',\n",
    "            'university': 'Bangalore University',\n",
    "            'start_date': 'August 2022',\n",
    "            'end_date': 'June 2025',\n",
    "            'cgpa': '8.82'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Experience (Empty Placeholder)\n",
    "    experience = [\n",
    "        {\n",
    "            'title': '',\n",
    "            'employment_type': '',\n",
    "            'company': '',\n",
    "            'start_date': '',\n",
    "            'end_date': '',\n",
    "            'location': '',\n",
    "            'description': ''\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Return Unified Profile\n",
    "    return {\n",
    "        'education': education,\n",
    "        'certifications': certifications,\n",
    "        'projects': projects,\n",
    "        'skills': skills,\n",
    "        'experience': experience\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717a15a-0f54-460a-a984-d7529975e646",
   "metadata": {},
   "source": [
    "### Initialize LLM (Google Gemini)\n",
    "\n",
    "This cell initializes the **Google Gemini 2.5 Flash** model using LangChain‚Äôs `ChatGoogleGenerativeAI` interface.\n",
    "\n",
    "Steps performed:\n",
    "1. Loads environment variables from the `.env` file (e.g., `GOOGLE_API_KEY`).\n",
    "2. Creates an instance of the Gemini model, which will serve as the main **language reasoning engine** for the CareerGraph AI system.\n",
    "\n",
    "This model will be responsible for all text understanding, response generation, and multi-agent coordination tasks within the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c5b65a7-30d0-4af5-aff3-ec7becc34bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables (e.g., GOOGLE_API_KEY) from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Google Gemini 2.5 Flash model\n",
    "# This model will handle reasoning, conversation, and decision-making tasks\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd843ded-eaa6-4f36-8cdf-09e502bcdec3",
   "metadata": {},
   "source": [
    "### Define Data Structures for User Profile and Agent State\n",
    "\n",
    "This cell defines the **typed data schemas** used throughout the CareerGraph AI system.  \n",
    "It uses Python‚Äôs `TypedDict` to strictly type-check dictionaries for different user-related entities and the global agent state.\n",
    "\n",
    "**Defined Classes:**\n",
    "- **Project** ‚Äì Represents user project details.\n",
    "- **Certification** ‚Äì Stores certification data.\n",
    "- **Education** ‚Äì Contains academic information.\n",
    "- **Experience** ‚Äì Captures professional experience details.\n",
    "- **State** ‚Äì Central structure that holds user input, selected agent action, contextual memory, and AI responses.\n",
    "\n",
    "These schemas ensure consistency and reliability when passing structured data between different AI agents and components.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81bebe72-c7ae-4e20-bc3c-5d9c14591938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import typing utilities for structured data representation\n",
    "from typing import TypedDict, Literal, List, Dict, Optional, Any\n",
    "\n",
    "# Define a schema for user projects\n",
    "class Project(TypedDict):\n",
    "    name: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    description: str\n",
    "\n",
    "# Define a schema for certifications\n",
    "class Certification(TypedDict):\n",
    "    name: str\n",
    "    organization: str\n",
    "\n",
    "# Define a schema for education details\n",
    "class Education(TypedDict):\n",
    "    degree: str\n",
    "    university: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    cgpa: float\n",
    "\n",
    "# Define a schema for professional experience\n",
    "class Experience(TypedDict):\n",
    "    title: str\n",
    "    employment_type: str\n",
    "    company: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    location: str\n",
    "    description: str\n",
    "\n",
    "# Define the central state structure used by agents\n",
    "class State(TypedDict):\n",
    "    # User input text or query\n",
    "    input_text: str\n",
    "\n",
    "    # Indicates which agent should handle the request\n",
    "    agent_action: Optional[\n",
    "        Literal[\n",
    "            \"course_recommender\",\n",
    "            \"project_recommender\",\n",
    "            \"interview_coach\",\n",
    "            \"learning_path_advisor\",\n",
    "            \"resume_builder\",\n",
    "            \"skill_analyzer\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Structured user information\n",
    "    skills: Optional[List[str]]\n",
    "    certifications: Optional[List[Certification]]\n",
    "    projects: Optional[List[Project]]\n",
    "    education: Optional[List[Education]]\n",
    "    experience: Optional[List[Experience]]\n",
    "\n",
    "    # Memory summary for conversation continuity\n",
    "    memory_summary: Optional[str]\n",
    "\n",
    "    # Model-generated response text\n",
    "    response: Optional[str]\n",
    "\n",
    "    # Additional metadata or runtime information\n",
    "    metadata: Optional[Dict]\n",
    "\n",
    "    # File path to generated resume (if applicable)\n",
    "    resume_path: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f0c2c-43bc-4e12-923f-ac3d1943fa9d",
   "metadata": {},
   "source": [
    "### Router Agent ‚Äî Context-Aware Query Dispatcher\n",
    "\n",
    "This cell defines the **Router Agent**, which intelligently decides which specialized sub-agent should process the user's query.  \n",
    "It uses the conversation‚Äôs **memory summary** to understand the user‚Äôs ongoing context and route the query more accurately.\n",
    "\n",
    "**How it works:**\n",
    "1. Combines the latest user input with the running `memory_summary`.\n",
    "2. Uses the LLM (Gemini) with structured output (`AgentType`) to decide which agent should handle the query.\n",
    "3. Updates the global `State` with the chosen agent action.\n",
    "\n",
    "**Possible Agents:**\n",
    "- `skill_analyzer` ‚Üí Analyze or improve user skills.\n",
    "- `project_recommender` ‚Üí Suggest or evaluate projects.\n",
    "- `course_recommender` ‚Üí Recommend courses or certifications.\n",
    "- `learning_path_advisor` ‚Üí Design structured learning paths.\n",
    "- `resume_builder` ‚Üí Build or optimize resumes.\n",
    "- `interview_coach` ‚Üí Assist with interview preparation.\n",
    "- `general` ‚Üí Any other general queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17e3f8ce-8724-437b-8765-919b669b9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class AgentType(BaseModel):\n",
    "    \"\"\"Schema defining which agent should handle the user's query.\"\"\"\n",
    "    agent_name: str = Field(\n",
    "        description=\"The name of the agent that should handle this query.\"\n",
    "    )\n",
    "\n",
    "def router(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Context-aware router for CareerGraph AI.\n",
    "    Determines which specialized agent should handle the user's query\n",
    "    using both the latest input and memory summary for context.\n",
    "    \"\"\"\n",
    "    \n",
    "    router_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the **RouterAgent** for CareerGraph AI ‚Äî an intelligent, LLM-powered career assistant.\n",
    "\n",
    "            Your goal:\n",
    "            - Analyze the user's current query and overall context (from memory).\n",
    "            - Determine which specialized agent should respond next.\n",
    "\n",
    "            **Available agents:**\n",
    "            1. \"skill_analyzer\" ‚Üí For analyzing or improving the user‚Äôs skills.\n",
    "            2. \"project_recommender\" ‚Üí For project ideas, feedback, or inspiration.\n",
    "            3. \"course_recommender\" ‚Üí For course or certification suggestions.\n",
    "            4. \"learning_path_advisor\" ‚Üí For structured learning or career roadmaps.\n",
    "            5. \"resume_builder\" ‚Üí For creating or optimizing resumes.\n",
    "            6. \"interview_coach\" ‚Üí For interview guidance and preparation.\n",
    "            7. \"general\" ‚Üí For general assistance outside the above.\n",
    "\n",
    "            **Output format:**\n",
    "            Return ONLY one of the agent names listed above as a plain string (no punctuation, no explanations).\n",
    "            Example:\n",
    "            skill_analyzer\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query: {input_text}\n",
    "\n",
    "            Memory summary of prior context: {memory_summary}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Chain combines the structured prompt with the Gemini model output\n",
    "    chain = router_prompt | llm.with_structured_output(AgentType)\n",
    "\n",
    "    # Invoke router with both input and memory summary\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": state[\"input_text\"],\n",
    "        \"memory_summary\": state.get(\"memory_summary\", \"\")\n",
    "    })\n",
    "\n",
    "    # Return updated state with the chosen agent\n",
    "    return {**state, \"agent_action\": response.agent_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd2b2ed-8e99-4d03-8a38-d809476db216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_action': 'skill_analyzer',\n",
      " 'input_text': 'where am i weak in my domain?',\n",
      " 'memory_summary': ''}\n"
     ]
    }
   ],
   "source": [
    "# Import pretty-print for readable console output\n",
    "from pprint import pprint\n",
    "\n",
    "# Test the router with a sample user query\n",
    "result = router({\n",
    "    'input_text': \"where am i weak in my domain?\",  # user input\n",
    "    # Optional memory summary (can be empty for now)\n",
    "    'memory_summary': \"\"\n",
    "})\n",
    "\n",
    "# Print the routing decision and updated state\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53137fc-2a09-4a75-b9b2-58ea858c0274",
   "metadata": {},
   "source": [
    "### User Profile Loader Agent\n",
    "\n",
    "This cell defines the **`get_user_profile`** agent node, responsible for retrieving and injecting user profile data into the shared **CareerGraph AI state**.\n",
    "\n",
    "**Purpose:**\n",
    "- Fetches the user‚Äôs stored information (skills, education, experience, etc.) from a data source (database, LinkedIn API, etc.).\n",
    "- Updates the global `State` so that downstream agents (e.g., resume builder, course recommender) can use accurate user information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a892ad8-479d-4a4e-a22e-e8396e86e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Loads the user profile from the database and updates the shared state.\n",
    "\n",
    "    This function fetches stored user data (skills, education, experience, etc.)\n",
    "    and injects it into the active CareerGraph AI state for downstream agents to use.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current CareerGraph AI state object.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state containing the user profile data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch user profile data from a database or API (to be implemented)\n",
    "    profile_data: Dict[str, Any] = get_user_profile_from()\n",
    "\n",
    "    # Update the shared state with profile details\n",
    "    state[\"skills\"] = profile_data.get(\"skills\", [])\n",
    "    state[\"education\"] = profile_data.get(\"education\", [])\n",
    "    state[\"experience\"] = profile_data.get(\"experience\", [])\n",
    "    state[\"projects\"] = profile_data.get(\"projects\", [])\n",
    "    state[\"certifications\"] = profile_data.get(\"certifications\", [])\n",
    "\n",
    "    # Return updated state for downstream use\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99cad237-7705-430a-895b-50609048fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_action': 'skill_analyzer',\n",
      " 'certifications': [{'name': 'Google Advanced Data Analytics',\n",
      "                     'organization': 'Google'},\n",
      "                    {'name': 'IBM Data Science Professional Certificate',\n",
      "                     'organization': 'IBM'},\n",
      "                    {'name': 'IBM RAG and Agentic AI: Build Next-Gen AI '\n",
      "                             'Systems',\n",
      "                     'organization': 'IBM'},\n",
      "                    {'name': 'Deep Learning', 'organization': 'DeepLearningAI'},\n",
      "                    {'name': 'Machine Learning',\n",
      "                     'organization': 'DeepLearningAI'},\n",
      "                    {'name': 'Mathematics for Machine Learning Specialization',\n",
      "                     'organization': 'Imperial College London'},\n",
      "                    {'name': 'Mathematics for Machine Learning and Data '\n",
      "                             'Science',\n",
      "                     'organization': 'DeepLearning.AI'},\n",
      "                    {'name': 'Python for Everybody Specialization',\n",
      "                     'organization': 'University of Michigan'}],\n",
      " 'education': [{'cgpa': '8.82',\n",
      "                'degree': 'Bachelor of Computer Applications',\n",
      "                'end_date': 'June 2025',\n",
      "                'start_date': 'August 2022',\n",
      "                'university': 'Bangalore University'}],\n",
      " 'experience': [{'company': '',\n",
      "                 'description': '',\n",
      "                 'employment_type': '',\n",
      "                 'end_date': '',\n",
      "                 'location': '',\n",
      "                 'start_date': '',\n",
      "                 'title': ''}],\n",
      " 'input_text': 'where am i weak in my domain?',\n",
      " 'memory_summary': '',\n",
      " 'projects': [{'description': 'Developed AI web app detecting biases (race, '\n",
      "                              'gender, profession, religion) with '\n",
      "                              'Bidirectional LSTM + Self Attention, achieving '\n",
      "                              '~98% accuracy via TensorFlow. Created Flask '\n",
      "                              'interface with Plotly for real-time '\n",
      "                              'visualization of bias probabilities and '\n",
      "                              'attention weights. '\n",
      "                              'https://github.com/sheb1lmsp/BiasBusterAI',\n",
      "               'end_date': 'October 2025',\n",
      "               'name': 'BiasBusterAI: Text Bias Detection System',\n",
      "               'start_date': 'October 2025'},\n",
      "              {'description': 'Developed a smart attendance management system '\n",
      "                              'using facial recognition to automate classroom '\n",
      "                              'attendance tracking. Leveraged PyTorch, MTCNN, '\n",
      "                              'and InceptionResNetV1 for face detection and '\n",
      "                              'recognition. Integrated with a Django web '\n",
      "                              'application featuring role-based dashboards. '\n",
      "                              'Streamlined attendance via group photo '\n",
      "                              'analysis. '\n",
      "                              'https://github.com/sheb1lmsp/smart_attend',\n",
      "               'end_date': 'August 2025',\n",
      "               'name': 'SmartAttend: An Automated Attendance Management System',\n",
      "               'start_date': 'May 2025'}],\n",
      " 'skills': ['Agentic AI',\n",
      "            'Retrieval Augmented Generation (RAG)',\n",
      "            'Large Language Models (LLMs)',\n",
      "            'LangChain',\n",
      "            'Django',\n",
      "            'LSTM',\n",
      "            'Flask',\n",
      "            'Transformers',\n",
      "            'RNN',\n",
      "            'TensorFlow',\n",
      "            'Supervised Learning',\n",
      "            'Unsupervised Learning',\n",
      "            'Pytorch',\n",
      "            'CNN',\n",
      "            'DBMS',\n",
      "            'DSA',\n",
      "            'Statistics',\n",
      "            'SQL',\n",
      "            'AI',\n",
      "            'Linear Algebra',\n",
      "            'Calculus',\n",
      "            'PCA',\n",
      "            'Python',\n",
      "            'Seaborn',\n",
      "            'Pandas',\n",
      "            'Numpy',\n",
      "            'Matplotlib',\n",
      "            'Scikit-learn',\n",
      "            'Data Analytics',\n",
      "            'Data Science',\n",
      "            'Machine Learning',\n",
      "            'Jupyter Notebook',\n",
      "            'Git']}\n"
     ]
    }
   ],
   "source": [
    "# Execute the user profile loading agent\n",
    "result = get_user_profile(result)\n",
    "\n",
    "# Display the updated state with loaded user information\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb581ba8-c0d6-46f6-aa70-c2ad59e0c889",
   "metadata": {},
   "source": [
    "### Course Recommender Agent\n",
    "\n",
    "This cell defines the **`course_recommender`** agent node.  \n",
    "It analyzes the user‚Äôs profile ‚Äî including skills, education, projects, and completed certifications ‚Äî  \n",
    "and suggests **3‚Äì5 personalized courses or certifications** that align with their goals.\n",
    "\n",
    "**Features:**\n",
    "- Avoids recommending courses or certifications already completed by the user.  \n",
    "- Uses `memory_summary` to maintain conversation context (e.g., previously discussed goals or learning paths).  \n",
    "- Returns concise, human-readable recommendations (no JSON or markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b5d5b1-23cf-4ff9-8e6e-5ab74f14a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def course_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Suggests relevant courses or certifications based on the user's profile.\n",
    "\n",
    "    This agent analyzes the user's current skills, education, projects, and certifications\n",
    "    to recommend 3‚Äì5 relevant courses or certifications from top learning platforms.\n",
    "    It avoids recommending duplicates or already-completed certifications.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current shared CareerGraph AI state.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with 'response' containing the course recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract key user info from the shared state\n",
    "    user_skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Define the prompt with memory and structured context\n",
    "    course_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the CourseRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your goal is to suggest highly relevant online courses or certifications\n",
    "            from platforms like Coursera, Udemy, edX, Google, or LinkedIn Learning\n",
    "            that help the user progress in their desired career path.\n",
    "\n",
    "            ‚ö†Ô∏è Rules:\n",
    "            - Do NOT recommend any course or certification the user already has or mentioned.\n",
    "            - Do NOT repeat known certifications.\n",
    "            - Focus on next-step or complementary learning.\n",
    "            - Recommend 3‚Äì5 courses only.\n",
    "            - For each course: include platform and one-line relevance.\n",
    "            - Output must be plain text (no JSON, no markdown).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or goal:\n",
    "            {user_query}\n",
    "\n",
    "            Memory summary (context from previous discussion):\n",
    "            {memory_summary}\n",
    "\n",
    "            User profile:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Projects: {projects}\n",
    "            - Completed Certifications: {certifications}\n",
    "\n",
    "            Return 3‚Äì5 unique, relevant courses in this format:\n",
    "\n",
    "            1. [Course Name] ‚Äî [Platform]\n",
    "               Why: [One-line reason]\n",
    "            2. [Course Name] ‚Äî [Platform]\n",
    "               Why: [One-line reason]\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Build the chain and get model output\n",
    "    chain = course_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store the AI's course recommendations in the shared state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    # Return updated state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b20fe632-323f-4a5f-83ac-bb480d9e435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Machine Learning Engineering for Production (MLOps) ‚Äî Coursera\n",
      "   Why: Focuses on deploying, maintaining, and scaling machine learning models in production environments, a crucial next step for your projects.\n",
      "2. Reinforcement Learning Specialization ‚Äî Coursera\n",
      "   Why: Introduces a fundamental and advanced branch of AI that is currently not covered in your extensive skill set.\n",
      "3. Google Cloud Professional Machine Learning Engineer Professional Certificate ‚Äî Coursera\n",
      "   Why: Provides practical experience in designing, building, and deploying ML systems on a leading cloud platform.\n",
      "4. Natural Language Processing Specialization ‚Äî Coursera\n",
      "   Why: Deepens your understanding of advanced NLP techniques and applications beyond LLMs and RAG, complementing your existing expertise in text-based AI.\n"
     ]
    }
   ],
   "source": [
    "# Execute the course recommender agent with the current user state\n",
    "result = course_recommender(result)\n",
    "\n",
    "# Print only the AI-generated course recommendations\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841a2ac-cb0d-4b54-b390-ad691db2fb62",
   "metadata": {},
   "source": [
    "### Project Recommender Agent\n",
    "\n",
    "This cell defines the **`project_recommender`** agent node.  \n",
    "It generates **3‚Äì5 creative and technically relevant project ideas** based on the user‚Äôs skills, education, experience, and overall career direction.\n",
    "\n",
    "**Features:**\n",
    "- Uses the `memory_summary` to maintain context from previous queries (e.g., user goals or prior interests).  \n",
    "- Avoids duplication with the user‚Äôs existing projects.  \n",
    "- Prioritizes challenging yet realistic ideas that strengthen the user‚Äôs portfolio.  \n",
    "- Returns responses in plain text format, suitable for direct display or storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b359398-27e9-46ba-9f55-3a3316f82a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Suggests creative and technically relevant project ideas for the user.\n",
    "\n",
    "    This agent analyzes the user's profile ‚Äî skills, education, experience, and goals ‚Äî\n",
    "    to recommend unique, high-impact project ideas that improve employability and portfolio depth.\n",
    "    It ensures that suggestions avoid overlap with existing projects and remain challenging yet achievable.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current shared CareerGraph AI state.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state containing project recommendations in 'response'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract user info and context from the shared state\n",
    "    user_skills = \", \".join(state.get(\"skills\", []))\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Define the project recommendation prompt\n",
    "    project_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ProjectRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Suggest unique, high-impact project ideas tailored to the user‚Äôs skills, experience, and goals.\n",
    "            - Help the user build portfolio depth and improve employability.\n",
    "\n",
    "            ‚öôÔ∏è Rules:\n",
    "            - Do NOT suggest projects too similar to existing ones.\n",
    "            - Suggest 3‚Äì5 creative, technically strong project ideas.\n",
    "            - Include a one-line reason why each project is valuable.\n",
    "            - Prefer ideas slightly above current skill level to encourage growth.\n",
    "            - Avoid trivial projects (e.g., \"To-Do App\", \"Calculator App\").\n",
    "            - Output plain text only ‚Äî no markdown, no JSON.\n",
    "\n",
    "            üéØ Example directions:\n",
    "            - For AI/ML skills ‚Üí applied ML, NLP, GenAI, automation.\n",
    "            - For software/dev ‚Üí scalable systems, developer tools.\n",
    "            - For data analytics ‚Üí dashboards, predictive models, business insights.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or goal:\n",
    "            {user_query}\n",
    "\n",
    "            Memory summary (context from prior interactions):\n",
    "            {memory_summary}\n",
    "\n",
    "            User profile:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Certifications: {certifications}\n",
    "            - Existing Projects: {projects}\n",
    "\n",
    "            Recommend 3‚Äì5 unique, creative projects the user can build next.\n",
    "            Each should include:\n",
    "            1. Project Name ‚Äî short and creative\n",
    "            2. Description ‚Äî one sentence\n",
    "            3. Why ‚Äî brief reason of value\n",
    "\n",
    "            Format strictly:\n",
    "            1. [Project Name]\n",
    "               Description: ...\n",
    "               Why: ...\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Build the chain and invoke with all context\n",
    "    chain = project_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store generated projects in the state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    # Return the updated state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c02030dd-890b-406d-834a-ac38b0a688df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. CogniFlow: Multi-Agent Workflow Automation System\n",
      "   Description: Develop an AI system where multiple specialized agents collaborate using RAG and tool integration to automate complex, multi-step tasks, such as research, content generation, or data analysis workflows.\n",
      "   Why: Demonstrates advanced agentic capabilities, complex system design, and practical application of LLMs beyond basic chat, showcasing sophisticated reasoning and planning.\n",
      "\n",
      "2. LLMServe: Scalable Inference & Observability\n",
      "   Description: Build a robust system for serving LLMs (or RAG pipelines) with auto-scaling capabilities, real-time performance monitoring, and A/B testing features on a cloud platform.\n",
      "   Why: Develops critical MLOps skills, showcasing the ability to deploy and manage production-grade AI systems efficiently and reliably.\n",
      "\n",
      "3. GraphRAG: Semantic Search & Reasoning Engine\n",
      "   Description: Implement a RAG system that integrates a knowledge graph (e.g., using Neo4j or similar) to provide more accurate, contextually rich, and explainable answers, especially for complex queries requiring structured information.\n",
      "   Why: Enhances RAG expertise with advanced knowledge representation and structured data integration, improving semantic understanding and explainability.\n"
     ]
    }
   ],
   "source": [
    "# This step uses the existing `result` state (which already includes user profile info)\n",
    "# and generates project ideas based on the user's skills, education, and experience.\n",
    "result = project_recommender(result)\n",
    "\n",
    "# This prints the list of creative and relevant project ideas for the user.\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724fed8-0bcd-44f0-824f-ac27944da39a",
   "metadata": {},
   "source": [
    "### Learning Path Advisor Agent\n",
    "\n",
    "This cell defines the **Learning Path Advisor** node of *CareerGraph AI*.  \n",
    "It creates a **personalized, step-by-step learning roadmap** to guide the user toward their desired career goal ‚Äî for example, becoming a *Data Scientist*, *Software Engineer*, or *AI Researcher*.\n",
    "\n",
    "#### What it does\n",
    "- Analyzes the user‚Äôs **skills**, **education**, **experience**, **certifications**, and **projects**.  \n",
    "- Uses the **user query** and **conversation memory** (`memory_summary`) to maintain continuity and context.  \n",
    "- Generates a **structured learning path** with milestones, skills to acquire, and resource recommendations.\n",
    "\n",
    "#### Key Features\n",
    "- Avoids recommending already-known skills or courses.  \n",
    "- Keeps roadmap **chronological**, **realistic**, and **measurable**.  \n",
    "- Includes **real-world project ideas** and **practical milestones**.  \n",
    "- Outputs a **formatted, human-readable roadmap** for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a61b3c24-9d0c-4916-9071-d3333d499839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningPath(BaseModel):\n",
    "    \"\"\"Structured schema representing a user's personalized learning roadmap.\"\"\"\n",
    "    target_role: str = Field(description=\"The career goal or target role the user aims to achieve.\")\n",
    "    required_skills: List[str] = Field(description=\"New or complementary skills the user needs to learn.\")\n",
    "    roadmap_steps: List[str] = Field(description=\"Ordered learning steps or milestones.\")\n",
    "    recommended_resources: List[str] = Field(description=\"Suggested learning materials or platforms.\")\n",
    "    summary: str = Field(description=\"A concise overview of the personalized learning roadmap.\")\n",
    "\n",
    "\n",
    "def learning_path_advisor(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Generates a step-by-step learning roadmap toward the user's target role.\n",
    "\n",
    "    This agent analyzes the user's background, known skills, and career goals to design\n",
    "    a progressive, goal-oriented learning plan. It avoids recommending already-known topics\n",
    "    and emphasizes real-world applicability and measurable growth.\n",
    "    \"\"\"\n",
    "    # Extract key profile elements from the shared state\n",
    "    user_input = state.get(\"input_text\", \"\")\n",
    "    known_skills = \", \".join(state.get(\"skills\", []))\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\") \n",
    "\n",
    "    # Build the structured LLM prompt\n",
    "    learning_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the LearningPath Advisor for CareerGraph AI.\n",
    "            Your role is to create personalized, practical, and efficient learning roadmaps\n",
    "            tailored to each user‚Äôs profile, skills, and career ambitions.\n",
    "\n",
    "            ‚úÖ Guidelines:\n",
    "            - Recommend only NEW or relevant skills (avoid known ones).\n",
    "            - Exclude any courses, certifications, or topics the user already completed.\n",
    "            - Keep steps chronological, measurable, and realistic.\n",
    "            - Include real-world projects, milestones, and portfolio tasks.\n",
    "            - Use the conversation memory to maintain context continuity.\n",
    "            - If no goal is provided, infer a likely target role.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {user_input}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Summary:\n",
    "            - Known Skills: {known_skills}\n",
    "            - Certifications: {certifications}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "\n",
    "            Provide a structured learning roadmap with:\n",
    "            - target_role\n",
    "            - required_skills (excluding known ones)\n",
    "            - roadmap_steps (in logical order)\n",
    "            - recommended_resources\n",
    "            - summary\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with structured output schema\n",
    "    chain = learning_prompt | llm.with_structured_output(LearningPath)\n",
    "\n",
    "    # Invoke the LLM with user context and memory\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"known_skills\": known_skills,\n",
    "        \"certifications\": certifications,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Format output into a user-friendly text block\n",
    "    formatted_output = (\n",
    "        f\"üéØ Target Role: {response.target_role}\\n\\n\"\n",
    "        f\"üß© Required Skills: {', '.join(response.required_skills)}\\n\\n\"\n",
    "        f\"ü™ú Learning Roadmap:\\n\" + \"\\n\".join([f\"- {step}\" for step in response.roadmap_steps]) + \"\\n\\n\"\n",
    "        f\"üìò Recommended Resources:\\n\" + \"\\n\".join([f\"- {r}\" for r in response.recommended_resources]) + \"\\n\\n\"\n",
    "        f\"üìù Summary: {response.summary}\"\n",
    "    )\n",
    "\n",
    "    # Store result back in shared state\n",
    "    state[\"response\"] = formatted_output\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a59aac7d-e2fc-42a8-b98d-c07fd4ce05a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Target Role: Machine Learning Engineer (MLOps Focus)\n",
      "\n",
      "üß© Required Skills: MLOps Principles, Docker, Kubernetes, Cloud Platforms (e.g., AWS SageMaker, GCP AI Platform, Azure ML), CI/CD for Machine Learning, Model Monitoring, Distributed Machine Learning, Advanced Prompt Engineering, LLM Fine-tuning for Production, System Design for AI\n",
      "\n",
      "ü™ú Learning Roadmap:\n",
      "- 1. Master MLOps Fundamentals: Understand the end-to-end lifecycle of ML models, from experimentation and development to deployment and maintenance in production.\n",
      "- 2. Containerization with Docker: Learn to package ML applications, dependencies, and environments into portable containers for consistent deployment.\n",
      "- 3. Orchestration with Kubernetes: Gain expertise in deploying, scaling, and managing containerized ML applications and services across clusters.\n",
      "- 4. Cloud-based ML Platforms: Acquire hands-on experience with a major cloud provider's managed ML services (e.g., AWS SageMaker, GCP AI Platform, Azure ML) for building, training, and deploying models.\n",
      "- 5. Implement CI/CD for Machine Learning: Develop automated pipelines for continuous integration, continuous delivery, and continuous training (CI/CD/CT) of ML models.\n",
      "- 6. Model Monitoring and Management: Learn to track model performance, detect data and concept drift, and manage different model versions in production.\n",
      "- 7. Build and Deploy an End-to-End LLM Application: Apply MLOps principles to deploy a sophisticated RAG or Agentic AI system, focusing on scalability and reliability.\n",
      "- 8. Explore Distributed Machine Learning: Understand techniques and frameworks (e.g., PySpark MLlib, Horovod) for training models on large datasets across distributed computing environments.\n",
      "- 9. Deepen LLM Deployment & Optimization: Focus on advanced techniques for optimizing LLM inference, fine-tuning large models efficiently, and managing associated costs in production.\n",
      "- 10. System Design for Scalable AI: Learn to design robust, fault-tolerant, and scalable AI systems, considering factors like latency, throughput, and cost-effectiveness.\n",
      "\n",
      "üìò Recommended Resources:\n",
      "- Online MLOps Specializations (e.g., Coursera's MLOps Specialization, Google Cloud's MLOps course, DeepLearning.AI's MLOps courses)\n",
      "- Official documentation for Docker, Kubernetes, and chosen cloud platforms (AWS, GCP, Azure)\n",
      "- Books: 'Building Machine Learning Powered Applications' by Emmanuel Ameisen, 'Designing Machine Learning Systems' by Chip Huyen\n",
      "- MLOps Community blogs and articles (e.g., Towards Data Science, Medium MLOps publications)\n",
      "- GitHub repositories with practical MLOps examples and open-source MLOps tools (e.g., MLflow, Kubeflow)\n",
      "\n",
      "üìù Summary: Your profile shows strong expertise in core AI/ML, especially in LLMs and RAG. To advance, this roadmap focuses on strengthening your MLOps, deployment, and scaling skills. The goal is to transition from model development to building and managing production-ready AI systems, targeting a Machine Learning Engineer role with an emphasis on operationalizing ML workflows. You'll learn to containerize, orchestrate, deploy on cloud platforms, and monitor your AI solutions, including advanced LLM applications.\n"
     ]
    }
   ],
   "source": [
    "# Generate a personalized learning roadmap based on the current user profile and memory summary\n",
    "result = learning_path_advisor(result)\n",
    "\n",
    "# Display the roadmap generated by the AI agent\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933488a4-2163-458e-a70c-ea7c566bce3b",
   "metadata": {},
   "source": [
    "### Skill Analyzer Agent\n",
    "\n",
    "This cell defines the **Skill Analyzer Agent** of *CareerGraph AI*.  \n",
    "It evaluates the user‚Äôs **skills**, **experience**, **projects**, and **certifications** to identify:  \n",
    "\n",
    "- **Core strengths** ‚Äî what the user is already good at  \n",
    "- **Weak or missing skills** ‚Äî areas that need improvement  \n",
    "- **Upskilling suggestions** ‚Äî new technologies or topics to learn  \n",
    "- **Recommended courses/certifications** ‚Äî specific ways to strengthen the profile  \n",
    "\n",
    "#### Features\n",
    "- Uses both the **user profile** and **memory summary** (conversation history)  \n",
    "- Generates **plain-text insights** ‚Äî no markdown, no JSON  \n",
    "- Focuses on **career relevance** and **technical growth**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8300d766-a206-42af-9b55-530e6d3265c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_analyzer(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Analyzes the user's skills, experience, and projects to identify\n",
    "    their core strengths, weaknesses, and upskilling opportunities.\n",
    "    \"\"\"\n",
    "    # Extract all relevant information from the state\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\") \n",
    "\n",
    "    # Build the structured prompt for the LLM\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the Skill Analyzer Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Analyze the user's skills, experience, and projects.\n",
    "            - Identify their strongest and most relevant skills.\n",
    "            - Highlight weak or missing skill areas.\n",
    "            - Recommend next-step upskilling opportunities (tools, frameworks, or soft skills).\n",
    "            - Use conversation memory to ensure continuity and avoid repeating suggestions.\n",
    "\n",
    "            Output format (plain text only):\n",
    "            Core Strengths:\n",
    "            - ...\n",
    "\n",
    "            Missing / Weak Skills:\n",
    "            - ...\n",
    "\n",
    "            Recommended Upskilling:\n",
    "            - ...\n",
    "\n",
    "            Suggested Courses / Certifications:\n",
    "            - ...\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Data:\n",
    "            - Skills: {skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "            - Certifications: {certifications}\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with the LLM and generate analysis\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"skills\": skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store the generated analysis in the state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e4aea6a-7753-411b-826d-84b573a2fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core Strengths:\n",
      "-   **Strong Foundational ML/DL:** Excellent grasp of core machine learning (Supervised, Unsupervised) and deep learning concepts (CNN, RNN, LSTM, Transformers), backed by certifications from DeepLearning.AI and Imperial College London.\n",
      "-   **Proficiency in Key Frameworks:** Hands-on experience with TensorFlow, PyTorch, Scikit-learn, Pandas, Numpy, Matplotlib, and Seaborn for data manipulation and model building.\n",
      "-   **Modern AI Paradigms:** Demonstrated understanding and application of Agentic AI, Retrieval Augmented Generation (RAG), and Large Language Models (LLMs).\n",
      "-   **Project-Based Application:** Successful development of complex AI projects like \"BiasBusterAI\" (Flask, Bi-LSTM, Self-Attention) and \"SmartAttend\" (Django, PyTorch, Facial Recognition), showcasing practical implementation skills.\n",
      "-   **Web Integration Skills:** Ability to integrate ML models into web applications using Flask and Django.\n",
      "-   **Solid Academic & Certification Background:** A strong academic record and numerous professional certifications from Google, IBM, DeepLearning.AI, and University of Michigan, indicating a dedicated learner.\n",
      "\n",
      "Missing / Weak Skills:\n",
      "-   **Real-world Industry Experience:** This is the most significant gap. The profile currently lacks any professional work experience (internships, full-time roles), which is crucial for applying theoretical knowledge in a business context, working in teams, and understanding production constraints.\n",
      "-   **MLOps & Production Deployment:** While you can build web interfaces, there's a lack of explicit skills in deploying, monitoring, and maintaining ML models at scale in production environments. This includes containerization (Docker), orchestration (Kubernetes), continuous integration/continuous deployment (CI/CD) for ML, and dedicated MLOps platforms (e.g., AWS SageMaker, Google Vertex AI, Azure ML).\n",
      "-   **Big Data Technologies:** No mention of distributed computing frameworks like Apache Spark, Hadoop, or data streaming technologies (e.g., Kafka) which are essential for handling and processing massive datasets in enterprise settings.\n",
      "-   **Advanced Cloud Proficiency:** While you might implicitly use some cloud services, explicit skills and certifications in specific cloud platforms (AWS, GCP, or Azure) beyond basic usage are not highlighted. Understanding cloud infrastructure and services for data and AI is vital.\n",
      "-   **Experiment Tracking & Model Versioning:** Skills in using tools like MLflow or Weights & Biases for managing experiments, tracking metrics, and versioning models are not listed.\n",
      "-   **Advanced Data Engineering:** While SQL and DBMS are listed, expertise in building robust ETL pipelines, data warehousing, or using data orchestration tools (e.g., Apache Airflow) is not evident.\n",
      "-   **System Design for ML:** Understanding how to design scalable, resilient, and cost-effective ML systems from an architectural perspective.\n",
      "\n",
      "Recommended Upskilling:\n",
      "-   **Gain Practical Industry Experience:** Actively seek internships, entry-level ML Engineer, Data Scientist, or AI Engineer roles. This is paramount for career growth.\n",
      "-   **Deep Dive into MLOps:** Focus on the lifecycle of ML models in production.\n",
      "-   **Master a Cloud Platform:** Choose one major cloud provider (AWS, GCP, or Azure) and become proficient in its data and ML services.\n",
      "-   **Learn Distributed Computing:** Understand how to process large datasets efficiently.\n",
      "-   **Develop System Design Acumen:** Learn to think about the architecture of ML solutions.\n",
      "\n",
      "Suggested Courses / Certifications:\n",
      "-   **MLOps Specialization/Courses:** Look for courses on Coursera, Udacity, or platforms like MLOps.community (e.g., \"Full Stack Deep Learning,\" \"Machine Learning Engineering for Production - MLOps\" by DeepLearning.AI).\n",
      "-   **Cloud Certifications:**\n",
      "    -   AWS Certified Machine Learning Specialty\n",
      "    -   Google Cloud Professional Machine Learning Engineer\n",
      "    -   Microsoft Certified: Azure AI Engineer Associate\n",
      "-   **Apache Spark Certification/Courses:**\n",
      "    -   Databricks Certified Associate Developer for Apache Spark\n",
      "    -   Courses on distributed data processing with Spark.\n",
      "-   **System Design for Machine Learning:** Explore books (e.g., \"Designing Machine Learning Systems\" by Chip Huyen) or courses specifically on ML system design.\n",
      "-   **Data Engineering Fundamentals:** Consider courses on Apache Airflow or advanced ETL concepts.\n"
     ]
    }
   ],
   "source": [
    "# Generate a detailed skill analysis based on user data and conversation memory\n",
    "result = skill_analyzer(result)\n",
    "\n",
    "# Display the AI-generated strengths, weaknesses, and upskilling suggestions\n",
    "print(result[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6877854-de57-4178-8acf-bfad0ec80694",
   "metadata": {},
   "source": [
    "### General Agent\n",
    "\n",
    "This cell defines the **General Agent** for *CareerGraph AI*.  \n",
    "It serves as a **fallback handler** for user queries that don‚Äôt belong to specific categories such as skill analysis, course recommendations, or resume building.\n",
    "\n",
    "#### What it does\n",
    "- Handles **general, open-ended, or advisory career-related questions**.  \n",
    "- Uses the **user‚Äôs memory summary** and **profile context** for continuity.  \n",
    "- If the user query is **not career-related**, it politely declines to answer by saying:  \n",
    "  > ‚ÄúSorry, I can only help with career-related topics.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "199207eb-aee9-4ac4-94de-c70d32cfa069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Responds to general or uncategorized user queries that don't match\n",
    "    specific agents like skill_analyzer, course_recommender, etc.\n",
    "    If the query is not career-related, it explicitly refuses to answer.\n",
    "    \"\"\"\n",
    "    # Extract relevant information from the shared state\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Build a general-purpose prompt for free-form conversation\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the General Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Handle general, open-ended, or advisory career-related queries.\n",
    "            - Use the user's background and memory summary for context.\n",
    "            - If the query is NOT career-related (e.g., about entertainment, math, jokes, or random facts),\n",
    "              clearly respond with: \"Sorry, I can only help with career-related topics.\"\n",
    "            - If it IS career-related, provide relevant, professional, and actionable advice.\n",
    "            - Always output plain text (no markdown, no JSON).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Data:\n",
    "            - Skills: {skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "            - Certifications: {certifications}\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with the LLM\n",
    "    chain = prompt | llm\n",
    "\n",
    "    # Invoke the model with user and memory context\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"skills\": skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Save and return the response\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336080a-7241-4c46-bd94-605ef3946cc4",
   "metadata": {},
   "source": [
    "### Job Description Parser Agent\n",
    "\n",
    "This agent extracts structured job information from any user-provided job description text.  \n",
    "It is a **non-interactive preprocessing node**, meaning it doesn‚Äôt produce a direct conversational response ‚Äî it simply enriches the shared `state` for downstream agents (like `resume_builder` or `interview_coach`).\n",
    "\n",
    "#### Responsibilities\n",
    "- Detect whether the input contains a job description or job posting.  \n",
    "- If yes, extract the following:\n",
    "  - **job_title**\n",
    "  - **company**\n",
    "  - **required_skills**\n",
    "  - **responsibilities**\n",
    "  - **experience_level**\n",
    "  - **summary (2 lines)**\n",
    "- If no job description is detected ‚Üí set `is_job_description = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "e954c40a-5784-4a41-8cd3-560118073d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class JobDescriptionModel(BaseModel):\n",
    "    \"\"\"Structured schema representing extracted details from a job description.\"\"\"\n",
    "    is_job_description: bool = Field(description=\"True if the input contains a job description or job post.\")\n",
    "    job_title: str = Field(default=\"\", description=\"The job title or role name, if mentioned.\")\n",
    "    company: str = Field(default=\"\", description=\"The company name, if mentioned.\")\n",
    "    required_skills: List[str] = Field(default_factory=list, description=\"List of technical or soft skills mentioned.\")\n",
    "    responsibilities: List[str] = Field(default_factory=list, description=\"List of key responsibilities or tasks mentioned.\")\n",
    "    experience_level: str = Field(default=\"\", description=\"Experience level (e.g., Entry-level, Mid-level, Senior), if detectable.\")\n",
    "    summary: str = Field(default=\"\", description=\"2-line summary of what the role is about.\")\n",
    "\n",
    "\n",
    "def job_description_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Parses structured job description data from the user's input.\n",
    "    \n",
    "    This agent:\n",
    "    - Detects whether the text is a job description.\n",
    "    - Extracts relevant structured information.\n",
    "    - Stores it under `state['metadata']['job_description']`.\n",
    "    - Does NOT produce direct output; it's used for internal data enrichment.\n",
    "    \"\"\"\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "\n",
    "    jd_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the JobDescriptionParser Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Detect if the user input contains a job description or job post.\n",
    "            - If yes, extract:\n",
    "              ‚Ä¢ job_title\n",
    "              ‚Ä¢ company\n",
    "              ‚Ä¢ required_skills\n",
    "              ‚Ä¢ responsibilities\n",
    "              ‚Ä¢ experience_level\n",
    "              ‚Ä¢ summary\n",
    "            - If not, set is_job_description=False.\n",
    "            - Be concise, structured, and factual.\n",
    "            - Return only structured output, no commentary or natural language text.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User Input:\\n{user_query}\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Structured LLM call\n",
    "    chain = jd_prompt | llm.with_structured_output(JobDescriptionModel)\n",
    "    response = chain.invoke({\"user_query\": user_query})\n",
    "\n",
    "    # Initialize metadata container if missing\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "    # Store extracted job description details\n",
    "    state[\"metadata\"][\"job_description\"] = response.model_dump()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "193cca7f-f9e0-4c8a-bc05-89906578f03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_job_description': False,\n",
       " 'job_title': '',\n",
       " 'company': '',\n",
       " 'required_skills': [],\n",
       " 'responsibilities': [],\n",
       " 'experience_level': '',\n",
       " 'summary': ''}"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Job Description Parser Agent\n",
    "result = job_description_parser(result)\n",
    "\n",
    "# Display the parsed job description section from metadata\n",
    "result[\"metadata\"][\"job_description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222632b9-eea6-4a37-8ac4-61995ff5160b",
   "metadata": {},
   "source": [
    "### Resume Text Extractor\n",
    "\n",
    "This function, `extract_resume_text()`, automatically detects whether the uploaded file is a **PDF** or a **Word document (.docx)** and extracts clean, plain text for further processing by CareerGraph AI agents such as the **Resume Builder** or **Interview Coach**.\n",
    "\n",
    "**Key Features:**\n",
    "- Supports both `.pdf` and `.docx` formats.  \n",
    "- Cleans and concatenates all textual content.  \n",
    "- Raises an error for unsupported file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "c01d32ac-0645-4b41-82e3-47060f2e4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF ‚Äî for reading PDF files\n",
    "from docx import Document  # for reading .docx files\n",
    "\n",
    "def extract_resume_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract clean text from resume files (.pdf or .docx).\n",
    "    \n",
    "    Automatically detects the file type and extracts textual content accordingly.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the resume file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted plain text content.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle PDF resume extraction\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = \"\"\n",
    "        with fitz.open(file_path) as pdf:\n",
    "            for page in pdf:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "        return text.strip()\n",
    "    \n",
    "    # Handle DOCX resume extraction\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = Document(file_path)\n",
    "        text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "        return text.strip()\n",
    "    \n",
    "    # Unsupported file format\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload a PDF or DOCX resume.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fc71a-db3c-4dc0-9cbf-caa1ee6112a4",
   "metadata": {},
   "source": [
    "### Resume Parser Agent\n",
    "\n",
    "This cell defines the **Resume Parser** node of CareerGraph AI.\n",
    "\n",
    "It uses an LLM to extract structured resume information such as:\n",
    "- Candidate details (name, email, phone, summary)\n",
    "- Professional data (skills, experience, education, certifications, projects)\n",
    "- Estimated total experience\n",
    "\n",
    "**Behavior:**\n",
    "- Parses resume text from the uploaded file path (`resume_path` in state).  \n",
    "- Enriches `state[\"metadata\"][\"resume_data\"]` with structured data.  \n",
    "- Does *not* overwrite top-level state fields like `skills` or `education`.  \n",
    "- Provides clean, machine-readable output for downstream agents such as:\n",
    "  - `resume_builder`\n",
    "  - `interview_coach`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "9f837740-d4a4-4449-92bd-c7a44e81d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeModel(BaseModel):\n",
    "    \"\"\"Structured schema representing parsed resume information.\"\"\"\n",
    "    is_resume: bool = Field(description=\"True if the input contains a resume.\")\n",
    "    name: str = Field(default=\"\", description=\"Full name of the candidate, if available.\")\n",
    "    email: str = Field(default=\"\", description=\"Email address of the candidate, if mentioned.\")\n",
    "    phone: str = Field(default=\"\", description=\"Phone number, if available.\")\n",
    "    summary: str = Field(default=\"\", description=\"Brief 2‚Äì3 line professional summary.\")\n",
    "    skills: List[str] = Field(default_factory=list, description=\"List of technical or soft skills.\")\n",
    "    education: List[str] = Field(default_factory=list, description=\"List of educational qualifications and institutions.\")\n",
    "    experience: List[str] = Field(default_factory=list, description=\"List of work experience entries or job roles.\")\n",
    "    certifications: List[str] = Field(default_factory=list, description=\"List of certifications or achievements.\")\n",
    "    projects: List[str] = Field(default_factory=list, description=\"List of project titles or brief descriptions.\")\n",
    "    total_experience_years: float = Field(default=0.0, description=\"Approximate total years of experience.\")\n",
    "\n",
    "\n",
    "def resume_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Resume Parser Agent ‚Äî extracts structured data from resumes.\n",
    "\n",
    "    This agent uses LLM parsing to convert unstructured resume text into a \n",
    "    structured dictionary that downstream agents (like Interview Coach or \n",
    "    Resume Builder) can consume.\n",
    "\n",
    "    Behavior:\n",
    "    - Reads text from the provided resume file (PDF or DOCX).\n",
    "    - Parses fields like name, email, skills, experience, etc.\n",
    "    - Stores results inside `state['metadata']['resume_data']`.\n",
    "    - Does NOT overwrite main state-level user info.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the file path to the user's uploaded resume\n",
    "    resume_path = state.get(\"resume_path\", None)\n",
    "\n",
    "    # Extract text using the unified loader\n",
    "    if resume_path is not None:\n",
    "        resume_text = extract_resume_text(resume_path)\n",
    "    else:\n",
    "        resume_text = \"None\"\n",
    "\n",
    "    # Build the LLM prompt\n",
    "    resume_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ResumeParser Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Analyze the provided resume text.\n",
    "            - Extract the following structured fields:\n",
    "              ‚Ä¢ name\n",
    "              ‚Ä¢ email\n",
    "              ‚Ä¢ phone\n",
    "              ‚Ä¢ summary\n",
    "              ‚Ä¢ skills\n",
    "              ‚Ä¢ education\n",
    "              ‚Ä¢ experience\n",
    "              ‚Ä¢ certifications\n",
    "              ‚Ä¢ projects\n",
    "              ‚Ä¢ total_experience_years (approx)\n",
    "            - If no resume data is found, make the 'is_resume' field False and leave other fields empty.\n",
    "            - Return output strictly following the structured schema (ResumeModel).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"Resume text:\\n{resume_text}\")\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt to the LLM with structured output\n",
    "    chain = resume_prompt | llm.with_structured_output(ResumeModel)\n",
    "    response = chain.invoke({\"resume_text\": resume_text})\n",
    "\n",
    "    # Store parsed data in the metadata section of the state\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "    state[\"metadata\"][\"resume_data\"] = response.model_dump()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "03a334a8-63c8-4903-9111-b34d5e59dd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_resume': True,\n",
       " 'name': 'Mohammed Shebil P',\n",
       " 'email': 'shebil.mohammed.p@gmail.com',\n",
       " 'phone': '+91 86062 19789',\n",
       " 'summary': 'Recent graduate with a strong foundation in Machine Learning, AI, and Data Analytics, seeking opportunities to apply technical skills in real-world projects.',\n",
       " 'skills': ['Machine Learning & AI: Supervised/Unsupervised Learning, NLP, Computer Vision, CNN, RNN, Transformers, LLMs, Generative AI',\n",
       "  'Programming: Python (Advanced), SQL (Intermediate)',\n",
       "  'Frameworks & Libraries: PyTorch, TensorFlow, Keras, Scikit-learn, XGBoost, Pandas, NumPy, PySpark',\n",
       "  'Web Development & Tools: Django, Flask, SQLite, Git',\n",
       "  'Cloud Platforms: Google Cloud Platform (Vertex AI, BigQuery)',\n",
       "  'Data Visualization: Seaborn, Matplotlib, Tableau, Power BI'],\n",
       " 'education': ['Bachelor of Computer Applications - Bangalore University, Bengaluru (August 2022 - June 2025)'],\n",
       " 'experience': [],\n",
       " 'certifications': ['Deep Learning Specialization, DeepLearning.AI, 2025',\n",
       "  'Machine Learning Specialization, DeepLearning.AI, 2025',\n",
       "  'Data Science Professional Certificate, IBM, 2025',\n",
       "  'Google Advanced Data Analytics, Google, 2025',\n",
       "  'Mathematics for Machine Learning and Data Science, DeepLearning.AI, 2025'],\n",
       " 'projects': ['Bias Buster AI: Text Bias Detection System - Independent Project (October 2025)',\n",
       "  'Smart Attend: An Automated Attendance Management System - Academic Project, Bangalore University (May 2025 - August 2025)'],\n",
       " 'total_experience_years': 0.0}"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy Test ‚Äî Parse Resume File\n",
    "file_path = \"../../../../Desktop/CV/Mohammed_Shebil_Resume.pdf\"\n",
    "\n",
    "# Run the resume parser agent with a test resume path\n",
    "result = resume_parser({'resume_path': file_path})\n",
    "\n",
    "# Display the parsed resume metadata\n",
    "result[\"metadata\"][\"resume_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872e18-1ec8-414a-819b-f6e0ce6354ee",
   "metadata": {},
   "source": [
    "### Interview Coach Agent\n",
    "\n",
    "#### Purpose\n",
    "This agent provides **personalized interview preparation guidance** by leveraging:\n",
    "- The **job description**,  \n",
    "- The **user‚Äôs resume**, or  \n",
    "- Other available **profile data** in the system state.\n",
    "\n",
    "It adapts dynamically based on which inputs are available:\n",
    "\n",
    "| Data Available | Behavior |\n",
    "|----------------|-----------|\n",
    "| Resume + JD | Tailored prep plan aligned with both |\n",
    "| Only JD | Focus on job role, company, and required skills |\n",
    "| Only Resume | Focus on candidate‚Äôs profile and experience |\n",
    "| None | Uses user‚Äôs state-level skill, project, and education info |\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Output Sections\n",
    "1. **Role Context** ‚Äî brief overview of the target job or domain.  \n",
    "2. **Key Focus Areas** ‚Äî what the candidate should emphasize.  \n",
    "3. **Likely Technical Questions** ‚Äî predicted domain-specific questions.  \n",
    "4. **Behavioral Questions** ‚Äî HR and situational queries.  \n",
    "5. **Preparation Tips** ‚Äî strategy and confidence advice.  \n",
    "6. **Bonus Recommendations** ‚Äî optional edge insights or resources.\n",
    "\n",
    "---\n",
    "\n",
    "#### How It Works\n",
    "The agent:\n",
    "1. Collects context from:\n",
    "   - `metadata[\"job_description\"]`\n",
    "   - `metadata[\"resume_data\"]`\n",
    "   - or `state` fields like skills, projects, education.\n",
    "2. Builds a unified **context summary** for the LLM.\n",
    "3. Uses a **structured prompt** to instruct the LLM.\n",
    "4. Returns a comprehensive, structured response in `state[\"response\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "5ae5e331-bb99-4405-ae96-375aefab2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def interview_coach(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI ‚Äî Interview Coach Agent\n",
    "\n",
    "    Dynamically generates interview guidance depending on available data:\n",
    "    - If both Job Description & Resume are available ‚Üí use both for a tailored prep plan  \n",
    "    - If only Job Description is available ‚Üí focus on that role and requirements  \n",
    "    - If only Resume is available ‚Üí focus on the candidate's background  \n",
    "    - If none are available ‚Üí use user's profile information from the state  \n",
    "\n",
    "    Also leverages conversation memory (`memory_summary`) for personalized continuity.\n",
    "\n",
    "    Output includes:\n",
    "    1. Role Context\n",
    "    2. Key Focus Areas\n",
    "    3. Likely Technical & Behavioral Questions\n",
    "    4. Preparation Tips\n",
    "    5. Bonus Recommendations (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract available metadata\n",
    "    metadata = state.get(\"metadata\", {})\n",
    "    job_description = metadata.get(\"job_description\", {})\n",
    "    resume_data = metadata.get(\"resume_data\", {})\n",
    "\n",
    "    # Fallback user profile data\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "\n",
    "    # Build the context dynamically based on available data\n",
    "    context_parts = []\n",
    "\n",
    "    # If Job Description exists\n",
    "    if job_description and job_description.get(\"is_job_description\", False):\n",
    "        context_parts.append(\n",
    "            \"Job Description Details:\\n\"\n",
    "            f\"- Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"- Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"- Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"- Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"- Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"- Summary: {job_description.get('summary', 'N/A')}\\n\"\n",
    "        )\n",
    "\n",
    "    # If Resume data exists\n",
    "    if resume_data and resume_data.get(\"is_resume\", False):\n",
    "        context_parts.append(\n",
    "            \"Resume Details:\\n\"\n",
    "            f\"- Name: {resume_data.get('name', 'N/A')}\\n\"\n",
    "            f\"- Skills: {', '.join(resume_data.get('skills', []))}\\n\"\n",
    "            f\"- Experience: {', '.join(resume_data.get('experience', []))}\\n\"\n",
    "            f\"- Projects: {', '.join(resume_data.get('projects', []))}\\n\"\n",
    "            f\"- Education: {', '.join(resume_data.get('education', []))}\\n\"\n",
    "        )\n",
    "\n",
    "    # Fallback ‚Äî if neither JD nor Resume is present\n",
    "    if not context_parts:\n",
    "        context_parts.append(\n",
    "            \"User Profile Summary:\\n\"\n",
    "            f\"- Skills: {', '.join(skills)}\\n\"\n",
    "            f\"- Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"- Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"- Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"- Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    # Combine all context parts\n",
    "    combined_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # Define the LLM prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the **Interview Coach Agent** for CareerGraph AI.\n",
    "\n",
    "            Your mission:\n",
    "            - Prepare the user for their upcoming job interview.\n",
    "            - Use Job Description and/or Resume data if provided.\n",
    "            - If only user profile info is available, base preparation on that.\n",
    "            - If `memory_summary` is provided, use it to recall the user's previous interactions.\n",
    "\n",
    "            Output structure:\n",
    "            1. Role Context (1‚Äì2 lines)\n",
    "            2. Key Focus Areas\n",
    "            3. Likely Technical Questions\n",
    "            4. Behavioral Questions\n",
    "            5. Preparation Tips\n",
    "            6. Bonus Recommendations (optional)\n",
    "\n",
    "            Keep tone professional, supportive, and realistic.\n",
    "            Output plain text only (no markdown or JSON).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            Memory Summary:\n",
    "            {memory_summary}\n",
    "\n",
    "            User Query:\n",
    "            {input_text}\n",
    "\n",
    "            Combined Context:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Execute the chain with context + memory\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"combined_context\": combined_context,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Save the LLM response to shared state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2725a-2049-49b2-bed3-cde673772a4c",
   "metadata": {},
   "source": [
    "### Resume Builder Agent\n",
    "\n",
    "#### Purpose\n",
    "The `resume_builder` agent of **CareerGraph AI** intelligently generates, enhances, and tailors resumes using available user data, resume uploads, job descriptions, and contextual memory.  \n",
    "It functions as a two-phase system ‚Äî **ATS Engine** and **HR Reviewer** ‚Äî ensuring the final output is both machine-readable and recruiter-ready.\n",
    "\n",
    "---\n",
    "\n",
    "#### Behavior Overview\n",
    "\n",
    "| Data Available | Agent Behavior |\n",
    "|----------------|----------------|\n",
    "| ‚úÖ Job Description + Resume | Creates a fully tailored resume matching the job requirements and user background. |\n",
    "| ‚úÖ Job Description only | Builds a new resume using stored profile data aligned with the JD. |\n",
    "| ‚úÖ Resume only | Improves and optimizes the uploaded resume for ATS and clarity. |\n",
    "| ‚ùå None available | Generates a professional resume purely from the user's stored profile data. |\n",
    "\n",
    "---\n",
    "\n",
    "#### Processing Logic\n",
    "\n",
    "1. **Context Extraction**  \n",
    "   - Reads job description and resume data from the `metadata` field.  \n",
    "   - Pulls additional details from user‚Äôs stored `skills`, `experience`, etc.  \n",
    "   - Integrates prior interaction context via `memory_summary`.\n",
    "\n",
    "2. **Dynamic Tailoring**  \n",
    "   - Chooses one of four logic branches depending on data presence.  \n",
    "   - Builds a context string combining JD, Resume, and/or Profile data.\n",
    "\n",
    "3. **LLM Prompting Flow**  \n",
    "   - Uses a system + human prompt via `ChatPromptTemplate`.  \n",
    "   - The system prompt defines a two-phase process:  \n",
    "     - **Phase 1 ‚Äî ATS Engine:** Generates 5 unique resume drafts.  \n",
    "     - **Phase 2 ‚Äî HR Reviewer:** Selects the single best version.\n",
    "\n",
    "4. **Final Output**  \n",
    "   - Produces **only one complete resume**, properly formatted.  \n",
    "   - The final result is stored in `state['response']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6eb9d904-d1d0-4cd9-a57d-8896ed5916d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def resume_builder(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI ‚Äî Resume Builder Agent (ATS + HR Selection Model)\n",
    "\n",
    "    Dynamically generates optimized resumes depending on available data:\n",
    "    - Both Job Description & Resume ‚Üí Tailor resume precisely to role.\n",
    "    - Only Job Description ‚Üí Create resume using profile data, tailored to JD.\n",
    "    - Only Resume ‚Üí Improve and optimize that resume.\n",
    "    - Neither ‚Üí Build complete resume only from user's profile (skills, experience, etc.).\n",
    "\n",
    "    Phase 1 ‚Äî ATS Engine:\n",
    "        ‚Ä¢ Produces 5 ATS-optimized variations (technical, managerial, concise, etc.)\n",
    "    Phase 2 ‚Äî HR Reviewer:\n",
    "        ‚Ä¢ Picks the most impactful version and outputs only that resume.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract metadata safely\n",
    "    metadata = state.get(\"metadata\", {})\n",
    "    job_description = metadata.get(\"job_description\", {})\n",
    "    resume_data = metadata.get(\"resume_data\", {})\n",
    "\n",
    "    # Extract general state info\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "\n",
    "    context_parts = []\n",
    "    tailoring_instruction = \"\"\n",
    "\n",
    "    # === Case 1: Both JD + Resume present ===\n",
    "    if job_description.get(\"is_job_description\") and resume_data.get(\"is_resume\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Both a job description and a resume are provided. \"\n",
    "            \"Tailor the resume exactly for this role, aligning achievements and skills \"\n",
    "            \"to the job‚Äôs required qualifications. Keep ATS optimization and clarity.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Job Description ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"Summary: {job_description.get('summary', '')}\\n\"\n",
    "        )\n",
    "        context_parts.append(\"\\n=== Existing Resume ===\\n\")\n",
    "        context_parts.append(str(resume_data))\n",
    "\n",
    "    # === Case 2: Only JD present ===\n",
    "    elif job_description.get(\"is_job_description\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Only a job description is available. Use the user‚Äôs stored profile \"\n",
    "            \"to build a tailored resume aligned to this job‚Äôs role and requirements.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Job Description ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "        )\n",
    "        context_parts.append(\"\\n=== User Profile ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    # === Case 3: Only Resume present ===\n",
    "    elif resume_data.get(\"is_resume\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Only a resume is provided. Improve and optimize it for ATS compliance and clarity. \"\n",
    "            \"Use user profile data to fill missing gaps or enhance detail.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Existing Resume ===\\n\")\n",
    "        context_parts.append(str(resume_data))\n",
    "        context_parts.append(\"\\n=== User Profile Supplement ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "        )\n",
    "\n",
    "    # === Case 4: No JD or Resume ===\n",
    "    else:\n",
    "        tailoring_instruction = (\n",
    "            \"No job description or resume provided. Build a professional, \"\n",
    "            \"ATS-optimized resume based solely on user profile data.\"\n",
    "        )\n",
    "        context_parts.append(\"=== User Profile ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_context = \"\\n\".join(context_parts)\n",
    "\n",
    "    # Prompt definition\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"\n",
    "            You are the Resume Builder Agent for CareerGraph AI.\n",
    "\n",
    "            {tailoring_instruction}\n",
    "\n",
    "            Use the information and memory context below to generate your output.\n",
    "\n",
    "            === PROCESS ===\n",
    "            Phase 1 ‚Äî ATS Engine:\n",
    "              ‚Ä¢ Generate FIVE unique, ATS-optimized resume drafts (technical, managerial, concise, academic, creative).\n",
    "              ‚Ä¢ Each follows this structure:\n",
    "                ======================\n",
    "                [FULL NAME]\n",
    "                [PROFESSIONAL SUMMARY]\n",
    "                [SKILLS]\n",
    "                [EXPERIENCE]\n",
    "                [PROJECTS]\n",
    "                [EDUCATION]\n",
    "                [CERTIFICATIONS]\n",
    "                ======================\n",
    "\n",
    "            Phase 2 ‚Äî HR Reviewer:\n",
    "              ‚Ä¢ Choose the ONE resume version most likely to pass both ATS and human review.\n",
    "              ‚Ä¢ Output ONLY that chosen resume.\n",
    "              ‚Ä¢ Do NOT include the other drafts or your reasoning.\n",
    "              ‚Ä¢ Keep formatting consistent and professional.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            Memory Summary:\n",
    "            {memory_summary}\n",
    "\n",
    "            User Query:\n",
    "            {input_text}\n",
    "\n",
    "            Context Information:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # LLM Execution\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"combined_context\": combined_context,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Save to state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b304c3-567a-47cd-a8ad-a342e3ef5263",
   "metadata": {},
   "source": [
    "### CareerGraph AI ‚Äî LangGraph Setup\n",
    "\n",
    "This file defines the **LangGraph agent workflow** for CareerGraph AI.  \n",
    "Each node is a distinct LLM-powered agent that specializes in different career services.\n",
    "\n",
    "---\n",
    "\n",
    "#### Node List\n",
    "\n",
    "| Node | Description |\n",
    "|------|--------------|\n",
    "| `get_user_profile` | Loads user details like skills, education, experience |\n",
    "| `router` | Routes user requests to appropriate agents |\n",
    "| `general` | Handles general queries or fallback cases |\n",
    "| `course_recommender` | Suggests online courses and certifications |\n",
    "| `project_recommender` | Suggests practical or portfolio projects |\n",
    "| `interview_coach` | Provides interview preparation and guidance |\n",
    "| `learning_path_advisor` | Builds skill-based learning paths |\n",
    "| `resume_builder` | Creates or tailors resumes dynamically |\n",
    "| `skill_analyzer` | Analyzes skills and finds gaps |\n",
    "| `resume_parser` | Extracts structured info from resumes |\n",
    "| `job_description_parser` | Extracts role details from job descriptions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "756f650c-b15c-43c9-9087-d836cc40a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Initialize the graph with the shared State type\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# Add All Agent Nodes\n",
    "graph.add_node('get_user_profile', get_user_profile)       # Fetch or initialize user data\n",
    "graph.add_node('router', router)                           # Routes user queries to agents\n",
    "graph.add_node('general', general)                         # Handles general/fallback queries\n",
    "graph.add_node('course_recommender', course_recommender)   # Suggests learning courses\n",
    "graph.add_node('project_recommender', project_recommender) # Recommends projects\n",
    "graph.add_node('interview_coach', interview_coach)         # Prepares user for interviews\n",
    "graph.add_node('learning_path_advisor', learning_path_advisor) # Suggests career learning paths\n",
    "graph.add_node('resume_builder', resume_builder)           # Builds or optimizes resumes\n",
    "graph.add_node('skill_analyzer', skill_analyzer)           # Analyzes user skills\n",
    "graph.add_node('resume_parser', resume_parser)             # Parses resume content\n",
    "graph.add_node('job_description_parser', job_description_parser) # Parses job descriptions\n",
    "\n",
    "# Define Graph Edges\n",
    "\n",
    "# Entry flow: start from profile setup ‚Üí router\n",
    "graph.add_edge(START, 'get_user_profile')\n",
    "graph.add_edge('get_user_profile', 'router')\n",
    "\n",
    "# Conditional routing from router to appropriate agent\n",
    "# If user asks for interview or resume tasks ‚Üí go to parser first\n",
    "graph.add_conditional_edges(\n",
    "    'router', \n",
    "    lambda state: state['agent_action'] if state['agent_action'] not in ['interview_coach', 'resume_builder'] else 'parser',\n",
    "    {\n",
    "        \"course_recommender\" : \"course_recommender\",\n",
    "        \"project_recommender\" : \"project_recommender\",\n",
    "        \"parser\" : \"resume_parser\",\n",
    "        \"learning_path_advisor\": \"learning_path_advisor\",\n",
    "        \"skill_analyzer\" : \"skill_analyzer\",\n",
    "        \"general\" : \"general\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parser flow: resume ‚Üí job description ‚Üí specific agent\n",
    "graph.add_edge('resume_parser', 'job_description_parser')\n",
    "graph.add_conditional_edges(\n",
    "    'job_description_parser',\n",
    "    lambda state: state['agent_action'],\n",
    "    {\n",
    "        'resume_builder' : 'resume_builder',\n",
    "        'interview_coach' : 'interview_coach'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define Endpoints\n",
    "graph.add_edge('course_recommender', END)\n",
    "graph.add_edge('project_recommender', END)\n",
    "graph.add_edge('interview_coach', END)\n",
    "graph.add_edge('learning_path_advisor', END)\n",
    "graph.add_edge('resume_builder', END)\n",
    "graph.add_edge('skill_analyzer', END)\n",
    "graph.add_edge('general', END)\n",
    "\n",
    "# Compile Final Graph App\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1645df2c-872a-4b92-bfff-040c41559b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7ff496001260>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the langgraph architecture\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0081ce-3f7c-4a1c-b984-ec8f646d7e23",
   "metadata": {},
   "source": [
    "### CareerGraph AI ‚Äî Conversational Memory Loop\n",
    "\n",
    "This module runs the **interactive chat system** for CareerGraph AI, enabling live, memory-aware conversations with LangGraph agents.\n",
    "\n",
    "---\n",
    "\n",
    "#### Core Features\n",
    "\n",
    "| Feature | Description |\n",
    "|----------|-------------|\n",
    "| **Exit Detection** | Uses a lightweight LLM prompt to check if user says ‚Äúbye‚Äù, ‚Äúexit‚Äù, etc. |\n",
    "| **Memory Management** | Keeps last 10 user‚ÄìAI exchanges in a rolling list |\n",
    "| **Summarized Context** | Compresses prior conversation into 5-sentence summary for continuity |\n",
    "| **Dynamic Agent Routing** | Sends each user query to the right agent via the LangGraph app |\n",
    "| **Persistent Flow** | Continues the session until user explicitly ends it |\n",
    "\n",
    "---\n",
    "\n",
    "#### Flow Overview\n",
    "\n",
    "1. **User Input ‚Üí Exit Check**  \n",
    "   - If user says ‚Äúbye‚Äù, AI politely ends the session.\n",
    "\n",
    "2. **Memory Update ‚Üí Context Summary**  \n",
    "   - Last 10 turns are summarized into a brief memory for context retention.\n",
    "\n",
    "3. **State Construction ‚Üí Agent Routing**  \n",
    "   - Creates a `state` dict with:\n",
    "     ```python\n",
    "     {\n",
    "       \"input_text\": <user message>,\n",
    "       \"memory_summary\": <context summary>\n",
    "     }\n",
    "     ```\n",
    "   - Sent to `app.invoke(state)` which routes through the LangGraph agent pipeline.\n",
    "\n",
    "4. **AI Response ‚Üí Memory Append**  \n",
    "   - Response displayed and appended to rolling memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "6c909205-cd21-406e-8c2a-99d096aa86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what should i learn next?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: üéØ Target Role: AI Engineer\n",
      "\n",
      "üß© Required Skills: Cloud Computing (AWS/GCP/Azure), Docker, Kubernetes, MLOps Principles and Tools (MLflow, DVC, Kubeflow), Prompt Engineering (Advanced), LLM Fine-tuning, Vector Databases (Pinecone, Weaviate, ChromaDB), API Design for Scalable AI Services, System Design for AI/ML Applications\n",
      "\n",
      "ü™ú Learning Roadmap:\n",
      "- Master Containerization with Docker: Learn Docker fundamentals (Dockerfiles, images, containers, volumes, networks). Project: Containerize an existing AI project (e.g., BiasBusterAI or SmartAttend) into a Docker image and run it locally.\n",
      "- Explore Cloud Platforms for AI Deployment: Choose one major cloud provider (e.g., AWS or GCP) and learn its AI/ML services (e.g., AWS SageMaker, GCP AI Platform). Focus on deploying a containerized ML model as an API endpoint. Project: Deploy a Dockerized ML model to a cloud platform, making it accessible via a REST API.\n",
      "- Implement MLOps Practices: Understand MLOps lifecycle (data versioning, model versioning, experiment tracking, CI/CD for ML). Learn and apply tools like MLflow for experiment tracking and model registry, or DVC for data/model versioning. Project: Integrate MLflow/DVC into one of your existing projects, tracking experiments and managing model versions.\n",
      "- Deep Dive into Vector Databases and Advanced RAG: Learn about different vector database architectures and their use cases. Implement RAG systems using a specific vector database (e.g., Pinecone, Weaviate) and LangChain. Explore advanced RAG techniques like multi-query, hybrid search, and RAG fusion. Project: Build an advanced RAG system for a specific domain (e.g., legal documents, medical research) using a vector database and a fine-tuned open-source LLM.\n",
      "- LLM Customization and Fine-tuning: Understand different strategies for customizing LLMs (PEFT, LoRA). Learn how to fine-tune open-source LLMs (e.g., Llama 2, Mistral) for specific tasks or datasets. Project: Fine-tune an open-source LLM on a custom dataset for a specific task (e.g., summarization, text generation in a particular style) and evaluate its performance.\n",
      "- Orchestrate AI Services with Kubernetes: Learn Kubernetes concepts (Pods, Deployments, Services, Ingress). Understand how to deploy and manage containerized AI applications at scale using Kubernetes. Project: Deploy your cloud-based AI service onto a Kubernetes cluster (e.g., EKS, GKE, Minikube for local testing).\n",
      "- Design and Implement Scalable AI Systems: Study system design principles for building robust, scalable, and fault-tolerant AI applications. Focus on API design for AI services, monitoring, and logging. Portfolio Project: Design and implement an end-to-end scalable AI system (e.g., a real-time recommendation engine, a complex multi-agent system) incorporating all learned skills, deploying it to the cloud with MLOps practices and monitoring.\n",
      "\n",
      "üìò Recommended Resources:\n",
      "- Online Courses: \"Docker and Kubernetes: The Complete Guide\" (Udemy), \"AWS Certified Machine Learning - Specialty\" (various platforms) or \"Google Cloud Professional Machine Learning Engineer\" (Coursera), \"MLOps Specialization\" (DeepLearning.AI), \"Building Systems with the ChatGPT API\" (DeepLearning.AI), \"Large Language Models: Application through Production\" (DeepLearning.AI).\n",
      "- Documentation: Official Docker, Kubernetes, AWS/GCP/Azure ML, MLflow, Pinecone/Weaviate documentation.\n",
      "- Books: \"Designing Machine Learning Systems\" by Chip Huyen, \"Building Machine Learning Powered Applications\" by Emmanuel Ameisen.\n",
      "- Blogs/Communities: Towards Data Science, MLflow blog, Hugging Face blog, MLOps Community, relevant GitHub repositories.\n",
      "\n",
      "üìù Summary: This roadmap aims to transition you from a strong ML/DL practitioner to a proficient AI Engineer capable of designing, developing, and deploying robust, scalable, and production-ready AI systems. It focuses on modern LLM and Agentic AI applications within cloud environments, emphasizing practical deployment, MLOps practices, and advanced customization techniques.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  how is docker and kubernetes?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Docker and Kubernetes are foundational technologies, especially crucial for your journey towards becoming a proficient AI Engineer, as we discussed previously. They are key components for building robust, scalable, and production-ready AI systems, particularly when deploying modern LLM applications in cloud environments.\n",
      "\n",
      "Here's a breakdown of how they are:\n",
      "\n",
      "Docker:\n",
      "Docker is a platform that uses OS-level virtualization to deliver software in packages called containers. These containers are isolated, portable environments that bundle an application and all its dependencies (code, runtime, system tools, libraries, settings) into a single, consistent unit.\n",
      "\n",
      "How it is for AI/ML Engineers:\n",
      "  Dependency Management: AI/ML projects often have complex dependencies (specific Python versions, libraries like TensorFlow or PyTorch, CUDA versions for GPU access). Docker ensures that your model runs in the exact environment it was developed in, preventing \"it works on my machine\" issues.\n",
      "  Reproducibility: It makes your experiments and deployments highly reproducible across different machines or environments (local, staging, production).\n",
      "  Portability: You can easily move your trained models and inference services from your local machine to a cloud server or an on-premise cluster without worrying about environment setup.\n",
      "  Resource Isolation: Containers provide a degree of isolation, which can be useful for managing resources when running multiple AI services on the same host.\n",
      "\n",
      "Kubernetes (K8s):\n",
      "Kubernetes is an open-source container orchestration system for automating deployment, scaling, and management of containerized applications. While Docker creates the individual containers, Kubernetes manages them at scale.\n",
      "\n",
      "How it is for AI/ML Engineers:\n",
      "  Scalability: AI applications, especially LLM services, often need to scale dynamically based on demand. Kubernetes can automatically scale the number of running containers (pods) up or down to handle varying loads, ensuring your application remains responsive.\n",
      "  High Availability: It can automatically restart failed containers, reschedule them on healthy nodes, and distribute traffic, ensuring your AI services are continuously available.\n",
      "  Resource Management: Kubernetes efficiently manages computing resources (CPU, memory, GPU) across a cluster, allowing you to run multiple AI workloads optimally.\n",
      "  Deployment Automation: It streamlines the deployment process for your AI models and services, enabling continuous integration and continuous deployment (CI/CD) pipelines.\n",
      "  MLOps Foundation: Kubernetes is a cornerstone of MLOps, providing the infrastructure for deploying, monitoring, and managing the lifecycle of machine learning models in production. This includes serving models via APIs, running batch inference jobs, and managing data pipelines.\n",
      "  GPU Scheduling: For deep learning workloads, Kubernetes can be configured to schedule containers on nodes with available GPUs, which is critical for performance.\n",
      "\n",
      "In summary, Docker provides the packaging and consistent environment for your AI applications, while Kubernetes provides the robust framework to deploy, manage, and scale those containerized applications in a production setting. Mastering both will equip you with essential skills for building and operating modern AI systems, aligning perfectly with the AI Engineer roadmap we outlined.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  great, thank you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Goodbye üëã\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Exit Detection Prompt\n",
    "exit_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a conversation manager.\n",
    "    Given the user's latest message, decide if the user wants to end the conversation.\n",
    "    \n",
    "    If the user clearly says something like \"bye\", \"thank you\", \"stop\", \"exit\", \"goodnight\", etc., \n",
    "    respond ONLY with the single word: \"exit\".\n",
    "    Otherwise, respond ONLY with the word: \"continue\"\n",
    "    \n",
    "    User message:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine prompt with the language model\n",
    "exit_chain = exit_prompt | llm\n",
    "\n",
    "# Initialize Memory\n",
    "memory = []          # Stores dialogue history\n",
    "memory_summary = \"\"  # Compressed summary of recent context\n",
    "\n",
    "# Main Conversation Loop\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Check if user wants to end the conversation\n",
    "    should_continue = exit_chain.invoke({'user_input': user_input}).content.strip()\n",
    "\n",
    "    if should_continue == \"exit\":\n",
    "        print(\"AI: Goodbye üëã\")\n",
    "        break  # Exit loop gracefully\n",
    "\n",
    "    # Retain only last 10 messages for context\n",
    "    memory = memory[-10:]\n",
    "\n",
    "    # If there‚Äôs existing conversation, summarize it\n",
    "    if memory:\n",
    "        summary_prompt = ChatPromptTemplate.from_template(\n",
    "            \"Summarize the key context of this conversation in 5 concise sentences:\\n\\n{conversation}\"\n",
    "        )\n",
    "        formatted = \"\\n\".join(memory)\n",
    "        chain = summary_prompt | llm\n",
    "        memory_summary = chain.invoke({\"conversation\": formatted}).content.strip()\n",
    "    else:\n",
    "        memory_summary = \"\"\n",
    "\n",
    "    # Build the current conversation state\n",
    "    state = {\n",
    "        \"input_text\": user_input,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    }\n",
    "\n",
    "    # Invoke the main LangGraph app (routes to the right agent)\n",
    "    result = app.invoke(state)\n",
    "    response = result.get(\"response\", \"(No response)\")\n",
    "\n",
    "    # Display AI response\n",
    "    print(f\"AI: {response}\\n\")\n",
    "\n",
    "    # Save latest messages in memory\n",
    "    memory.append(f\"User: {user_input}\")\n",
    "    memory.append(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db483a94-ac98-470c-8858-78e06fa5a951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3939c4-6065-4445-8763-7f05cc5bb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/get_profile.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/get_profile.py\n",
    "def get_user_profile_from():\n",
    "    \"\"\"\n",
    "    Returns a structured dummy user profile for internal testing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing user data with the following keys:\n",
    "              - 'education'\n",
    "              - 'certifications'\n",
    "              - 'projects'\n",
    "              - 'skills'\n",
    "              - 'experience'\n",
    "    \"\"\"\n",
    "\n",
    "    # Skills\n",
    "    skills = [\n",
    "        'Agentic AI', 'Retrieval Augmented Generation (RAG)', 'Large Language Models (LLMs)',\n",
    "        'LangChain', 'Django', 'LSTM', 'Flask', 'Transformers', 'RNN', 'TensorFlow',\n",
    "        'Supervised Learning', 'Unsupervised Learning', 'Pytorch', 'CNN', 'DBMS', 'DSA',\n",
    "        'Statistics', 'SQL', 'AI', 'Linear Algebra', 'Calculus', 'PCA', 'Python',\n",
    "        'Seaborn', 'Pandas', 'Numpy', 'Matplotlib', 'Scikit-learn', 'Data Analytics',\n",
    "        'Data Science', 'Machine Learning', 'Jupyter Notebook', 'Git'\n",
    "    ]\n",
    "\n",
    "    # Certifications\n",
    "    certifications = [\n",
    "        {'name': 'Google Advanced Data Analytics', 'organization': 'Google'},\n",
    "        {'name': 'IBM Data Science Professional Certificate', 'organization': 'IBM'},\n",
    "        {'name': 'IBM RAG and Agentic AI: Build Next-Gen AI Systems', 'organization': 'IBM'},\n",
    "        {'name': 'Deep Learning', 'organization': 'DeepLearningAI'},\n",
    "        {'name': 'Machine Learning', 'organization': 'DeepLearningAI'},\n",
    "        {'name': 'Mathematics for Machine Learning Specialization', 'organization': 'Imperial College London'},\n",
    "        {'name': 'Mathematics for Machine Learning and Data Science', 'organization': 'DeepLearning.AI'},\n",
    "        {'name': 'Python for Everybody Specialization', 'organization': 'University of Michigan'}\n",
    "    ]\n",
    "\n",
    "    # Projects\n",
    "    projects = [\n",
    "        {\n",
    "            'name': 'BiasBusterAI: Text Bias Detection System',\n",
    "            'start_date': 'October 2025',\n",
    "            'end_date': 'October 2025',\n",
    "            'description': (\n",
    "                'Developed AI web app detecting biases (race, gender, profession, religion) '\n",
    "                'with Bidirectional LSTM + Self Attention, achieving ~98% accuracy via TensorFlow. '\n",
    "                'Created Flask interface with Plotly for real-time visualization of bias probabilities '\n",
    "                'and attention weights. https://github.com/sheb1lmsp/BiasBusterAI'\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            'name': 'SmartAttend: An Automated Attendance Management System',\n",
    "            'start_date': 'May 2025',\n",
    "            'end_date': 'August 2025',\n",
    "            'description': (\n",
    "                'Developed a smart attendance management system using facial recognition to automate '\n",
    "                'classroom attendance tracking. Leveraged PyTorch, MTCNN, and InceptionResNetV1 for '\n",
    "                'face detection and recognition. Integrated with a Django web application featuring '\n",
    "                'role-based dashboards. Streamlined attendance via group photo analysis. '\n",
    "                'https://github.com/sheb1lmsp/smart_attend'\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Education\n",
    "    education = [\n",
    "        {\n",
    "            'degree': 'Bachelor of Computer Applications',\n",
    "            'university': 'Bangalore University',\n",
    "            'start_date': 'August 2022',\n",
    "            'end_date': 'June 2025',\n",
    "            'cgpa': '8.82'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Experience (Empty Placeholder)\n",
    "    experience = [\n",
    "        {\n",
    "            'title': '',\n",
    "            'employment_type': '',\n",
    "            'company': '',\n",
    "            'start_date': '',\n",
    "            'end_date': '',\n",
    "            'location': '',\n",
    "            'description': ''\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Return Unified Profile\n",
    "    return {\n",
    "        'education': education,\n",
    "        'certifications': certifications,\n",
    "        'projects': projects,\n",
    "        'skills': skills,\n",
    "        'experience': experience\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8628bc-a3a9-4339-a223-4200410177ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/llm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/llm.py\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def get_llm(model_name: str = \"gemini-2.5-flash\"):\n",
    "    \"\"\"\n",
    "    Initialize and return a Google Generative AI (Gemini) model instance.\n",
    "\n",
    "    Args:\n",
    "        model_name (str, optional): Model name to use. Defaults to \"gemini-2.5-flash\".\n",
    "\n",
    "    Returns:\n",
    "        ChatGoogleGenerativeAI: Initialized LLM instance for use across the project.\n",
    "    \"\"\"\n",
    "    # Load environment variables (expects GOOGLE_API_KEY in .env)\n",
    "    load_dotenv()\n",
    "\n",
    "    # Initialize the LLM with the specified model name\n",
    "    llm = ChatGoogleGenerativeAI(model=model_name)\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6e3a3c-748c-49a5-a877-8647b9788d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../state.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../state.py\n",
    "# Import typing utilities for structured data representation\n",
    "from typing import TypedDict, Literal, List, Dict, Optional, Any\n",
    "\n",
    "# Define a schema for user projects\n",
    "class Project(TypedDict):\n",
    "    name: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    description: str\n",
    "\n",
    "# Define a schema for certifications\n",
    "class Certification(TypedDict):\n",
    "    name: str\n",
    "    organization: str\n",
    "\n",
    "# Define a schema for education details\n",
    "class Education(TypedDict):\n",
    "    degree: str\n",
    "    university: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    cgpa: float\n",
    "\n",
    "# Define a schema for professional experience\n",
    "class Experience(TypedDict):\n",
    "    title: str\n",
    "    employment_type: str\n",
    "    company: str\n",
    "    start_date: str\n",
    "    end_date: str\n",
    "    location: str\n",
    "    description: str\n",
    "\n",
    "# Define the central state structure used by agents\n",
    "class State(TypedDict):\n",
    "    # User input text or query\n",
    "    input_text: str\n",
    "\n",
    "    # Indicates which agent should handle the request\n",
    "    agent_action: Optional[\n",
    "        Literal[\n",
    "            \"course_recommender\",\n",
    "            \"project_recommender\",\n",
    "            \"interview_coach\",\n",
    "            \"learning_path_advisor\",\n",
    "            \"resume_builder\",\n",
    "            \"skill_analyzer\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Structured user information\n",
    "    skills: Optional[List[str]]\n",
    "    certifications: Optional[List[Certification]]\n",
    "    projects: Optional[List[Project]]\n",
    "    education: Optional[List[Education]]\n",
    "    experience: Optional[List[Experience]]\n",
    "\n",
    "    # Memory summary for conversation continuity\n",
    "    memory_summary: Optional[str]\n",
    "\n",
    "    # Model-generated response text\n",
    "    response: Optional[str]\n",
    "\n",
    "    # Additional metadata or runtime information\n",
    "    metadata: Optional[Dict]\n",
    "\n",
    "    # File path to generated resume (if applicable)\n",
    "    resume_path: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18276672-ce9b-4116-b7b7-8a36595b8e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/router_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/router_agent.py\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "class AgentType(BaseModel):\n",
    "    \"\"\"Schema defining which agent should handle the user's query.\"\"\"\n",
    "    agent_name: str = Field(\n",
    "        description=\"The name of the agent that should handle this query.\"\n",
    "    )\n",
    "\n",
    "def router(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Context-aware router for CareerGraph AI.\n",
    "    Determines which specialized agent should handle the user's query\n",
    "    using both the latest input and memory summary for context.\n",
    "    \"\"\"\n",
    "    \n",
    "    router_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the **RouterAgent** for CareerGraph AI ‚Äî an intelligent, LLM-powered career assistant.\n",
    "\n",
    "            Your goal:\n",
    "            - Analyze the user's current query and overall context (from memory).\n",
    "            - Determine which specialized agent should respond next.\n",
    "\n",
    "            **Available agents:**\n",
    "            1. \"skill_analyzer\" ‚Üí For analyzing or improving the user‚Äôs skills.\n",
    "            2. \"project_recommender\" ‚Üí For project ideas, feedback, or inspiration.\n",
    "            3. \"course_recommender\" ‚Üí For course or certification suggestions.\n",
    "            4. \"learning_path_advisor\" ‚Üí For structured learning or career roadmaps.\n",
    "            5. \"resume_builder\" ‚Üí For creating or optimizing resumes.\n",
    "            6. \"interview_coach\" ‚Üí For interview guidance and preparation.\n",
    "            7. \"general\" ‚Üí For general assistance outside the above.\n",
    "\n",
    "            **Output format:**\n",
    "            Return ONLY one of the agent names listed above as a plain string (no punctuation, no explanations).\n",
    "            Example:\n",
    "            skill_analyzer\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query: {input_text}\n",
    "\n",
    "            Memory summary of prior context: {memory_summary}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Chain combines the structured prompt with the Gemini model output\n",
    "    chain = router_prompt | llm.with_structured_output(AgentType)\n",
    "\n",
    "    # Invoke router with both input and memory summary\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": state[\"input_text\"],\n",
    "        \"memory_summary\": state.get(\"memory_summary\", \"\")\n",
    "    })\n",
    "\n",
    "    # Return updated state with the chosen agent\n",
    "    return {**state, \"agent_action\": response.agent_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d314703-76ac-4c6b-b09f-b79b58f93c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/get_user_profile_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/get_user_profile_agent.py\n",
    "from state import State\n",
    "from utils.get_profile import get_user_profile_from\n",
    "\n",
    "def get_user_profile(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Loads the user profile from the database and updates the shared state.\n",
    "\n",
    "    This function fetches stored user data (skills, education, experience, etc.)\n",
    "    and injects it into the active CareerGraph AI state for downstream agents to use.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current CareerGraph AI state object.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state containing the user profile data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch user profile data from a database or API (to be implemented)\n",
    "    profile_data: Dict[str, Any] = get_user_profile_from()\n",
    "\n",
    "    # Update the shared state with profile details\n",
    "    state[\"skills\"] = profile_data.get(\"skills\", [])\n",
    "    state[\"education\"] = profile_data.get(\"education\", [])\n",
    "    state[\"experience\"] = profile_data.get(\"experience\", [])\n",
    "    state[\"projects\"] = profile_data.get(\"projects\", [])\n",
    "    state[\"certifications\"] = profile_data.get(\"certifications\", [])\n",
    "\n",
    "    # Return updated state for downstream use\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d84a0c8d-968f-4f72-b0ea-f98a583b2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/course_recommender_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/course_recommender_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def course_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Suggests relevant courses or certifications based on the user's profile.\n",
    "\n",
    "    This agent analyzes the user's current skills, education, projects, and certifications\n",
    "    to recommend 3‚Äì5 relevant courses or certifications from top learning platforms.\n",
    "    It avoids recommending duplicates or already-completed certifications.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current shared CareerGraph AI state.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state with 'response' containing the course recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract key user info from the shared state\n",
    "    user_skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Define the prompt with memory and structured context\n",
    "    course_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the CourseRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your goal is to suggest highly relevant online courses or certifications\n",
    "            from platforms like Coursera, Udemy, edX, Google, or LinkedIn Learning\n",
    "            that help the user progress in their desired career path.\n",
    "\n",
    "            ‚ö†Ô∏è Rules:\n",
    "            - Do NOT recommend any course or certification the user already has or mentioned.\n",
    "            - Do NOT repeat known certifications.\n",
    "            - Focus on next-step or complementary learning.\n",
    "            - Recommend 3‚Äì5 courses only.\n",
    "            - For each course: include platform and one-line relevance.\n",
    "            - Output must be plain text (no JSON, no markdown).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or goal:\n",
    "            {user_query}\n",
    "\n",
    "            Memory summary (context from previous discussion):\n",
    "            {memory_summary}\n",
    "\n",
    "            User profile:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Projects: {projects}\n",
    "            - Completed Certifications: {certifications}\n",
    "\n",
    "            Return 3‚Äì5 unique, relevant courses in this format:\n",
    "\n",
    "            1. [Course Name] ‚Äî [Platform]\n",
    "               Why: [One-line reason]\n",
    "            2. [Course Name] ‚Äî [Platform]\n",
    "               Why: [One-line reason]\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Build the chain and get model output\n",
    "    chain = course_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store the AI's course recommendations in the shared state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    # Return updated state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91334349-a52c-4246-b0fc-577775f89ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/project_recommender_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/project_recommender_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def project_recommender(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Suggests creative and technically relevant project ideas for the user.\n",
    "\n",
    "    This agent analyzes the user's profile ‚Äî skills, education, experience, and goals ‚Äî\n",
    "    to recommend unique, high-impact project ideas that improve employability and portfolio depth.\n",
    "    It ensures that suggestions avoid overlap with existing projects and remain challenging yet achievable.\n",
    "\n",
    "    Args:\n",
    "        state (State): The current shared CareerGraph AI state.\n",
    "\n",
    "    Returns:\n",
    "        State: Updated state containing project recommendations in 'response'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract user info and context from the shared state\n",
    "    user_skills = \", \".join(state.get(\"skills\", []))\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Define the project recommendation prompt\n",
    "    project_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ProjectRecommender Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Suggest unique, high-impact project ideas tailored to the user‚Äôs skills, experience, and goals.\n",
    "            - Help the user build portfolio depth and improve employability.\n",
    "\n",
    "            ‚öôÔ∏è Rules:\n",
    "            - Do NOT suggest projects too similar to existing ones.\n",
    "            - Suggest 3‚Äì5 creative, technically strong project ideas.\n",
    "            - Include a one-line reason why each project is valuable.\n",
    "            - Prefer ideas slightly above current skill level to encourage growth.\n",
    "            - Avoid trivial projects (e.g., \"To-Do App\", \"Calculator App\").\n",
    "            - Output plain text only ‚Äî no markdown, no JSON.\n",
    "\n",
    "            üéØ Example directions:\n",
    "            - For AI/ML skills ‚Üí applied ML, NLP, GenAI, automation.\n",
    "            - For software/dev ‚Üí scalable systems, developer tools.\n",
    "            - For data analytics ‚Üí dashboards, predictive models, business insights.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User query or goal:\n",
    "            {user_query}\n",
    "\n",
    "            Memory summary (context from prior interactions):\n",
    "            {memory_summary}\n",
    "\n",
    "            User profile:\n",
    "            - Skills: {user_skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Certifications: {certifications}\n",
    "            - Existing Projects: {projects}\n",
    "\n",
    "            Recommend 3‚Äì5 unique, creative projects the user can build next.\n",
    "            Each should include:\n",
    "            1. Project Name ‚Äî short and creative\n",
    "            2. Description ‚Äî one sentence\n",
    "            3. Why ‚Äî brief reason of value\n",
    "\n",
    "            Format strictly:\n",
    "            1. [Project Name]\n",
    "               Description: ...\n",
    "               Why: ...\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Build the chain and invoke with all context\n",
    "    chain = project_prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"user_query\": user_query,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"user_skills\": user_skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store generated projects in the state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    # Return the updated state\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08e947c3-6094-43ba-abe4-9fa335e4fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/learning_path_advisor_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/learning_path_advisor_agent.py\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "from typing import List\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "class LearningPath(BaseModel):\n",
    "    \"\"\"Structured schema representing a user's personalized learning roadmap.\"\"\"\n",
    "    target_role: str = Field(description=\"The career goal or target role the user aims to achieve.\")\n",
    "    required_skills: List[str] = Field(description=\"New or complementary skills the user needs to learn.\")\n",
    "    roadmap_steps: List[str] = Field(description=\"Ordered learning steps or milestones.\")\n",
    "    recommended_resources: List[str] = Field(description=\"Suggested learning materials or platforms.\")\n",
    "    summary: str = Field(description=\"A concise overview of the personalized learning roadmap.\")\n",
    "\n",
    "\n",
    "def learning_path_advisor(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Generates a step-by-step learning roadmap toward the user's target role.\n",
    "\n",
    "    This agent analyzes the user's background, known skills, and career goals to design\n",
    "    a progressive, goal-oriented learning plan. It avoids recommending already-known topics\n",
    "    and emphasizes real-world applicability and measurable growth.\n",
    "    \"\"\"\n",
    "    # Extract key profile elements from the shared state\n",
    "    user_input = state.get(\"input_text\", \"\")\n",
    "    known_skills = \", \".join(state.get(\"skills\", []))\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\") \n",
    "\n",
    "    # Build the structured LLM prompt\n",
    "    learning_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the LearningPath Advisor for CareerGraph AI.\n",
    "            Your role is to create personalized, practical, and efficient learning roadmaps\n",
    "            tailored to each user‚Äôs profile, skills, and career ambitions.\n",
    "\n",
    "            ‚úÖ Guidelines:\n",
    "            - Recommend only NEW or relevant skills (avoid known ones).\n",
    "            - Exclude any courses, certifications, or topics the user already completed.\n",
    "            - Keep steps chronological, measurable, and realistic.\n",
    "            - Include real-world projects, milestones, and portfolio tasks.\n",
    "            - Use the conversation memory to maintain context continuity.\n",
    "            - If no goal is provided, infer a likely target role.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {user_input}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Summary:\n",
    "            - Known Skills: {known_skills}\n",
    "            - Certifications: {certifications}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "\n",
    "            Provide a structured learning roadmap with:\n",
    "            - target_role\n",
    "            - required_skills (excluding known ones)\n",
    "            - roadmap_steps (in logical order)\n",
    "            - recommended_resources\n",
    "            - summary\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with structured output schema\n",
    "    chain = learning_prompt | llm.with_structured_output(LearningPath)\n",
    "\n",
    "    # Invoke the LLM with user context and memory\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"known_skills\": known_skills,\n",
    "        \"certifications\": certifications,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Format output into a user-friendly text block\n",
    "    formatted_output = (\n",
    "        f\"üéØ Target Role: {response.target_role}\\n\\n\"\n",
    "        f\"üß© Required Skills: {', '.join(response.required_skills)}\\n\\n\"\n",
    "        f\"ü™ú Learning Roadmap:\\n\" + \"\\n\".join([f\"- {step}\" for step in response.roadmap_steps]) + \"\\n\\n\"\n",
    "        f\"üìò Recommended Resources:\\n\" + \"\\n\".join([f\"- {r}\" for r in response.recommended_resources]) + \"\\n\\n\"\n",
    "        f\"üìù Summary: {response.summary}\"\n",
    "    )\n",
    "\n",
    "    # Store result back in shared state\n",
    "    state[\"response\"] = formatted_output\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69756644-b802-46e8-a48e-607e47909f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/skill_analyzer_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/skill_analyzer_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def skill_analyzer(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Analyzes the user's skills, experience, and projects to identify\n",
    "    their core strengths, weaknesses, and upskilling opportunities.\n",
    "    \"\"\"\n",
    "    # Extract all relevant information from the state\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\") \n",
    "\n",
    "    # Build the structured prompt for the LLM\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the Skill Analyzer Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Analyze the user's skills, experience, and projects.\n",
    "            - Identify their strongest and most relevant skills.\n",
    "            - Highlight weak or missing skill areas.\n",
    "            - Recommend next-step upskilling opportunities (tools, frameworks, or soft skills).\n",
    "            - Use conversation memory to ensure continuity and avoid repeating suggestions.\n",
    "\n",
    "            Output format (plain text only):\n",
    "            Core Strengths:\n",
    "            - ...\n",
    "\n",
    "            Missing / Weak Skills:\n",
    "            - ...\n",
    "\n",
    "            Recommended Upskilling:\n",
    "            - ...\n",
    "\n",
    "            Suggested Courses / Certifications:\n",
    "            - ...\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Data:\n",
    "            - Skills: {skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "            - Certifications: {certifications}\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with the LLM and generate analysis\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"skills\": skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Store the generated analysis in the state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ace209d5-983c-4ecf-8861-096970f202bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/general_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/general_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def general(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Responds to general or uncategorized user queries that don't match\n",
    "    specific agents like skill_analyzer, course_recommender, etc.\n",
    "    If the query is not career-related, it explicitly refuses to answer.\n",
    "    \"\"\"\n",
    "    # Extract relevant information from the shared state\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "\n",
    "    # Build a general-purpose prompt for free-form conversation\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the General Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Handle general, open-ended, or advisory career-related queries.\n",
    "            - Use the user's background and memory summary for context.\n",
    "            - If the query is NOT career-related (e.g., about entertainment, math, jokes, or random facts),\n",
    "              clearly respond with: \"Sorry, I can only help with career-related topics.\"\n",
    "            - If it IS career-related, provide relevant, professional, and actionable advice.\n",
    "            - Always output plain text (no markdown, no JSON).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            User Query: {input_text}\n",
    "\n",
    "            Memory Summary: {memory_summary}\n",
    "\n",
    "            Profile Data:\n",
    "            - Skills: {skills}\n",
    "            - Education: {education}\n",
    "            - Experience: {experience}\n",
    "            - Projects: {projects}\n",
    "            - Certifications: {certifications}\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt with the LLM\n",
    "    chain = prompt | llm\n",
    "\n",
    "    # Invoke the model with user and memory context\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"memory_summary\": memory_summary,\n",
    "        \"skills\": skills,\n",
    "        \"education\": education,\n",
    "        \"experience\": experience,\n",
    "        \"projects\": projects,\n",
    "        \"certifications\": certifications,\n",
    "    })\n",
    "\n",
    "    # Save and return the response\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "400eba69-4073-49c8-85fc-f3f6b336e209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/job_description_parser_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/job_description_parser_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "class JobDescriptionModel(BaseModel):\n",
    "    \"\"\"Structured schema representing extracted details from a job description.\"\"\"\n",
    "    is_job_description: bool = Field(description=\"True if the input contains a job description or job post.\")\n",
    "    job_title: str = Field(default=\"\", description=\"The job title or role name, if mentioned.\")\n",
    "    company: str = Field(default=\"\", description=\"The company name, if mentioned.\")\n",
    "    required_skills: List[str] = Field(default_factory=list, description=\"List of technical or soft skills mentioned.\")\n",
    "    responsibilities: List[str] = Field(default_factory=list, description=\"List of key responsibilities or tasks mentioned.\")\n",
    "    experience_level: str = Field(default=\"\", description=\"Experience level (e.g., Entry-level, Mid-level, Senior), if detectable.\")\n",
    "    summary: str = Field(default=\"\", description=\"2-line summary of what the role is about.\")\n",
    "\n",
    "\n",
    "def job_description_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Agent Node: Parses structured job description data from the user's input.\n",
    "    \n",
    "    This agent:\n",
    "    - Detects whether the text is a job description.\n",
    "    - Extracts relevant structured information.\n",
    "    - Stores it under `state['metadata']['job_description']`.\n",
    "    - Does NOT produce direct output; it's used for internal data enrichment.\n",
    "    \"\"\"\n",
    "    user_query = state.get(\"input_text\", \"\")\n",
    "\n",
    "    jd_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the JobDescriptionParser Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Detect if the user input contains a job description or job post.\n",
    "            - If yes, extract:\n",
    "              ‚Ä¢ job_title\n",
    "              ‚Ä¢ company\n",
    "              ‚Ä¢ required_skills\n",
    "              ‚Ä¢ responsibilities\n",
    "              ‚Ä¢ experience_level\n",
    "              ‚Ä¢ summary\n",
    "            - If not, set is_job_description=False.\n",
    "            - Be concise, structured, and factual.\n",
    "            - Return only structured output, no commentary or natural language text.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"User Input:\\n{user_query}\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Structured LLM call\n",
    "    chain = jd_prompt | llm.with_structured_output(JobDescriptionModel)\n",
    "    response = chain.invoke({\"user_query\": user_query})\n",
    "\n",
    "    # Initialize metadata container if missing\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "    # Store extracted job description details\n",
    "    state[\"metadata\"][\"job_description\"] = response.model_dump()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bcdd2e33-9300-49fe-a3c8-6badefd11ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../utils/extract_resume.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../utils/extract_resume.py\n",
    "import fitz  # PyMuPDF ‚Äî for reading PDF files\n",
    "from docx import Document  # for reading .docx files\n",
    "\n",
    "def extract_resume_text(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract clean text from resume files (.pdf or .docx).\n",
    "    \n",
    "    Automatically detects the file type and extracts textual content accordingly.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the resume file.\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted plain text content.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle PDF resume extraction\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = \"\"\n",
    "        with fitz.open(file_path) as pdf:\n",
    "            for page in pdf:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "        return text.strip()\n",
    "    \n",
    "    # Handle DOCX resume extraction\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = Document(file_path)\n",
    "        text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "        return text.strip()\n",
    "    \n",
    "    # Unsupported file format\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload a PDF or DOCX resume.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5aac4bc-7216-4eae-99be-60ad10710731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/resume_parser_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/resume_parser_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "from utils.extract_resume import extract_resume_text\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "class ResumeModel(BaseModel):\n",
    "    \"\"\"Structured schema representing parsed resume information.\"\"\"\n",
    "    is_resume: bool = Field(description=\"True if the input contains a resume.\")\n",
    "    name: str = Field(default=\"\", description=\"Full name of the candidate, if available.\")\n",
    "    email: str = Field(default=\"\", description=\"Email address of the candidate, if mentioned.\")\n",
    "    phone: str = Field(default=\"\", description=\"Phone number, if available.\")\n",
    "    summary: str = Field(default=\"\", description=\"Brief 2‚Äì3 line professional summary.\")\n",
    "    skills: List[str] = Field(default_factory=list, description=\"List of technical or soft skills.\")\n",
    "    education: List[str] = Field(default_factory=list, description=\"List of educational qualifications and institutions.\")\n",
    "    experience: List[str] = Field(default_factory=list, description=\"List of work experience entries or job roles.\")\n",
    "    certifications: List[str] = Field(default_factory=list, description=\"List of certifications or achievements.\")\n",
    "    projects: List[str] = Field(default_factory=list, description=\"List of project titles or brief descriptions.\")\n",
    "    total_experience_years: float = Field(default=0.0, description=\"Approximate total years of experience.\")\n",
    "\n",
    "\n",
    "def resume_parser(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Resume Parser Agent ‚Äî extracts structured data from resumes.\n",
    "\n",
    "    This agent uses LLM parsing to convert unstructured resume text into a \n",
    "    structured dictionary that downstream agents (like Interview Coach or \n",
    "    Resume Builder) can consume.\n",
    "\n",
    "    Behavior:\n",
    "    - Reads text from the provided resume file (PDF or DOCX).\n",
    "    - Parses fields like name, email, skills, experience, etc.\n",
    "    - Stores results inside `state['metadata']['resume_data']`.\n",
    "    - Does NOT overwrite main state-level user info.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the file path to the user's uploaded resume\n",
    "    resume_path = state.get(\"resume_path\", None)\n",
    "\n",
    "    # Extract text using the unified loader\n",
    "    if resume_path is not None:\n",
    "        resume_text = extract_resume_text(resume_path)\n",
    "    else:\n",
    "        resume_text = \"None\"\n",
    "\n",
    "    # Build the LLM prompt\n",
    "    resume_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the ResumeParser Agent for CareerGraph AI.\n",
    "\n",
    "            Your task:\n",
    "            - Analyze the provided resume text.\n",
    "            - Extract the following structured fields:\n",
    "              ‚Ä¢ name\n",
    "              ‚Ä¢ email\n",
    "              ‚Ä¢ phone\n",
    "              ‚Ä¢ summary\n",
    "              ‚Ä¢ skills\n",
    "              ‚Ä¢ education\n",
    "              ‚Ä¢ experience\n",
    "              ‚Ä¢ certifications\n",
    "              ‚Ä¢ projects\n",
    "              ‚Ä¢ total_experience_years (approx)\n",
    "            - If no resume data is found, make the 'is_resume' field False and leave other fields empty.\n",
    "            - Return output strictly following the structured schema (ResumeModel).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"Resume text:\\n{resume_text}\")\n",
    "    ])\n",
    "\n",
    "    # Chain the prompt to the LLM with structured output\n",
    "    chain = resume_prompt | llm.with_structured_output(ResumeModel)\n",
    "    response = chain.invoke({\"resume_text\": resume_text})\n",
    "\n",
    "    # Store parsed data in the metadata section of the state\n",
    "    if state.get(\"metadata\") is None:\n",
    "        state[\"metadata\"] = {}\n",
    "\n",
    "    state[\"metadata\"][\"resume_data\"] = response.model_dump()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77e28ff4-13c1-46dd-a505-af0793c9cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/interview_coach_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/interview_coach_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def interview_coach(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI ‚Äî Interview Coach Agent\n",
    "\n",
    "    Dynamically generates interview guidance depending on available data:\n",
    "    - If both Job Description & Resume are available ‚Üí use both for a tailored prep plan  \n",
    "    - If only Job Description is available ‚Üí focus on that role and requirements  \n",
    "    - If only Resume is available ‚Üí focus on the candidate's background  \n",
    "    - If none are available ‚Üí use user's profile information from the state  \n",
    "\n",
    "    Also leverages conversation memory (`memory_summary`) for personalized continuity.\n",
    "\n",
    "    Output includes:\n",
    "    1. Role Context\n",
    "    2. Key Focus Areas\n",
    "    3. Likely Technical & Behavioral Questions\n",
    "    4. Preparation Tips\n",
    "    5. Bonus Recommendations (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract available metadata\n",
    "    metadata = state.get(\"metadata\", {})\n",
    "    job_description = metadata.get(\"job_description\", {})\n",
    "    resume_data = metadata.get(\"resume_data\", {})\n",
    "\n",
    "    # Fallback user profile data\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "\n",
    "    # Build the context dynamically based on available data\n",
    "    context_parts = []\n",
    "\n",
    "    # If Job Description exists\n",
    "    if job_description and job_description.get(\"is_job_description\", False):\n",
    "        context_parts.append(\n",
    "            \"Job Description Details:\\n\"\n",
    "            f\"- Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"- Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"- Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"- Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"- Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"- Summary: {job_description.get('summary', 'N/A')}\\n\"\n",
    "        )\n",
    "\n",
    "    # If Resume data exists\n",
    "    if resume_data and resume_data.get(\"is_resume\", False):\n",
    "        context_parts.append(\n",
    "            \"Resume Details:\\n\"\n",
    "            f\"- Name: {resume_data.get('name', 'N/A')}\\n\"\n",
    "            f\"- Skills: {', '.join(resume_data.get('skills', []))}\\n\"\n",
    "            f\"- Experience: {', '.join(resume_data.get('experience', []))}\\n\"\n",
    "            f\"- Projects: {', '.join(resume_data.get('projects', []))}\\n\"\n",
    "            f\"- Education: {', '.join(resume_data.get('education', []))}\\n\"\n",
    "        )\n",
    "\n",
    "    # Fallback ‚Äî if neither JD nor Resume is present\n",
    "    if not context_parts:\n",
    "        context_parts.append(\n",
    "            \"User Profile Summary:\\n\"\n",
    "            f\"- Skills: {', '.join(skills)}\\n\"\n",
    "            f\"- Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"- Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"- Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"- Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    # Combine all context parts\n",
    "    combined_context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    # Define the LLM prompt\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            You are the **Interview Coach Agent** for CareerGraph AI.\n",
    "\n",
    "            Your mission:\n",
    "            - Prepare the user for their upcoming job interview.\n",
    "            - Use Job Description and/or Resume data if provided.\n",
    "            - If only user profile info is available, base preparation on that.\n",
    "            - If `memory_summary` is provided, use it to recall the user's previous interactions.\n",
    "\n",
    "            Output structure:\n",
    "            1. Role Context (1‚Äì2 lines)\n",
    "            2. Key Focus Areas\n",
    "            3. Likely Technical Questions\n",
    "            4. Behavioral Questions\n",
    "            5. Preparation Tips\n",
    "            6. Bonus Recommendations (optional)\n",
    "\n",
    "            Keep tone professional, supportive, and realistic.\n",
    "            Output plain text only (no markdown or JSON).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            Memory Summary:\n",
    "            {memory_summary}\n",
    "\n",
    "            User Query:\n",
    "            {input_text}\n",
    "\n",
    "            Combined Context:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Execute the chain with context + memory\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"combined_context\": combined_context,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Save the LLM response to shared state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c8beafc-6ec5-4634-82e5-b81a64841eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../agents/resume_builder_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../agents/resume_builder_agent.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from state import State\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "def resume_builder(state: State) -> State:\n",
    "    \"\"\"\n",
    "    CareerGraph AI ‚Äî Resume Builder Agent (ATS + HR Selection Model)\n",
    "\n",
    "    Dynamically generates optimized resumes depending on available data:\n",
    "    - Both Job Description & Resume ‚Üí Tailor resume precisely to role.\n",
    "    - Only Job Description ‚Üí Create resume using profile data, tailored to JD.\n",
    "    - Only Resume ‚Üí Improve and optimize that resume.\n",
    "    - Neither ‚Üí Build complete resume only from user's profile (skills, experience, etc.).\n",
    "\n",
    "    Phase 1 ‚Äî ATS Engine:\n",
    "        ‚Ä¢ Produces 5 ATS-optimized variations (technical, managerial, concise, etc.)\n",
    "    Phase 2 ‚Äî HR Reviewer:\n",
    "        ‚Ä¢ Picks the most impactful version and outputs only that resume.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract metadata safely\n",
    "    metadata = state.get(\"metadata\", {})\n",
    "    job_description = metadata.get(\"job_description\", {})\n",
    "    resume_data = metadata.get(\"resume_data\", {})\n",
    "\n",
    "    # Extract general state info\n",
    "    input_text = state.get(\"input_text\", \"\")\n",
    "    memory_summary = state.get(\"memory_summary\", \"\")\n",
    "    skills = state.get(\"skills\", [])\n",
    "    experience = state.get(\"experience\", [])\n",
    "    education = state.get(\"education\", [])\n",
    "    projects = state.get(\"projects\", [])\n",
    "    certifications = state.get(\"certifications\", [])\n",
    "\n",
    "    context_parts = []\n",
    "    tailoring_instruction = \"\"\n",
    "\n",
    "    # === Case 1: Both JD + Resume present ===\n",
    "    if job_description.get(\"is_job_description\") and resume_data.get(\"is_resume\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Both a job description and a resume are provided. \"\n",
    "            \"Tailor the resume exactly for this role, aligning achievements and skills \"\n",
    "            \"to the job‚Äôs required qualifications. Keep ATS optimization and clarity.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Job Description ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "            f\"Summary: {job_description.get('summary', '')}\\n\"\n",
    "        )\n",
    "        context_parts.append(\"\\n=== Existing Resume ===\\n\")\n",
    "        context_parts.append(str(resume_data))\n",
    "\n",
    "    # === Case 2: Only JD present ===\n",
    "    elif job_description.get(\"is_job_description\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Only a job description is available. Use the user‚Äôs stored profile \"\n",
    "            \"to build a tailored resume aligned to this job‚Äôs role and requirements.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Job Description ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Role: {job_description.get('job_title', 'N/A')}\\n\"\n",
    "            f\"Company: {job_description.get('company', 'N/A')}\\n\"\n",
    "            f\"Required Skills: {', '.join(job_description.get('required_skills', []))}\\n\"\n",
    "            f\"Responsibilities: {', '.join(job_description.get('responsibilities', []))}\\n\"\n",
    "            f\"Experience Level: {job_description.get('experience_level', 'N/A')}\\n\"\n",
    "        )\n",
    "        context_parts.append(\"\\n=== User Profile ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    # === Case 3: Only Resume present ===\n",
    "    elif resume_data.get(\"is_resume\"):\n",
    "        tailoring_instruction = (\n",
    "            \"Only a resume is provided. Improve and optimize it for ATS compliance and clarity. \"\n",
    "            \"Use user profile data to fill missing gaps or enhance detail.\"\n",
    "        )\n",
    "        context_parts.append(\"=== Existing Resume ===\\n\")\n",
    "        context_parts.append(str(resume_data))\n",
    "        context_parts.append(\"\\n=== User Profile Supplement ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "        )\n",
    "\n",
    "    # === Case 4: No JD or Resume ===\n",
    "    else:\n",
    "        tailoring_instruction = (\n",
    "            \"No job description or resume provided. Build a professional, \"\n",
    "            \"ATS-optimized resume based solely on user profile data.\"\n",
    "        )\n",
    "        context_parts.append(\"=== User Profile ===\\n\")\n",
    "        context_parts.append(\n",
    "            f\"Skills: {', '.join(skills)}\\n\"\n",
    "            f\"Experience: {', '.join([exp.get('title', 'N/A') + ' at ' + exp.get('company', 'N/A') for exp in experience])}\\n\"\n",
    "            f\"Education: {', '.join([edu.get('degree', 'N/A') + ' at ' + edu.get('university', 'N/A') for edu in education])}\\n\"\n",
    "            f\"Projects: {', '.join([p.get('name', 'N/A') for p in projects])}\\n\"\n",
    "            f\"Certifications: {', '.join([c.get('name', 'N/A') for c in certifications])}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_context = \"\\n\".join(context_parts)\n",
    "\n",
    "    # Prompt definition\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"\n",
    "            You are the Resume Builder Agent for CareerGraph AI.\n",
    "\n",
    "            {tailoring_instruction}\n",
    "\n",
    "            Use the information and memory context below to generate your output.\n",
    "\n",
    "            === PROCESS ===\n",
    "            Phase 1 ‚Äî ATS Engine:\n",
    "              ‚Ä¢ Generate FIVE unique, ATS-optimized resume drafts (technical, managerial, concise, academic, creative).\n",
    "              ‚Ä¢ Each follows this structure:\n",
    "                ======================\n",
    "                [FULL NAME]\n",
    "                [PROFESSIONAL SUMMARY]\n",
    "                [SKILLS]\n",
    "                [EXPERIENCE]\n",
    "                [PROJECTS]\n",
    "                [EDUCATION]\n",
    "                [CERTIFICATIONS]\n",
    "                ======================\n",
    "\n",
    "            Phase 2 ‚Äî HR Reviewer:\n",
    "              ‚Ä¢ Choose the ONE resume version most likely to pass both ATS and human review.\n",
    "              ‚Ä¢ Output ONLY that chosen resume.\n",
    "              ‚Ä¢ Do NOT include the other drafts or your reasoning.\n",
    "              ‚Ä¢ Keep formatting consistent and professional.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"\n",
    "            Memory Summary:\n",
    "            {memory_summary}\n",
    "\n",
    "            User Query:\n",
    "            {input_text}\n",
    "\n",
    "            Context Information:\n",
    "            {combined_context}\n",
    "            \"\"\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # LLM Execution\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\n",
    "        \"input_text\": input_text,\n",
    "        \"combined_context\": combined_context,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    })\n",
    "\n",
    "    # Save to state\n",
    "    state[\"response\"] = response.content.strip()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a89a2b5-0461-4633-8904-d9e44767ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../graph_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../graph_builder.py\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Import all agents and nodes\n",
    "from agents.router_agent import router\n",
    "from agents.general_agent import general\n",
    "from agents.course_recommender_agent import course_recommender\n",
    "from agents.project_recommender_agent import project_recommender\n",
    "from agents.interview_coach_agent import interview_coach\n",
    "from agents.learning_path_advisor_agent import learning_path_advisor\n",
    "from agents.resume_builder_agent import resume_builder\n",
    "from agents.skill_analyzer_agent import skill_analyzer\n",
    "from agents.resume_parser_agent import resume_parser\n",
    "from agents.job_description_parser_agent import job_description_parser\n",
    "from agents.get_user_profile_agent import get_user_profile\n",
    "from state import State \n",
    "\n",
    "\n",
    "def build_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Build and compile the full CareerGraph AI workflow using LangGraph.\n",
    "\n",
    "    This function:\n",
    "    - Initializes the state graph with the shared `State` class.\n",
    "    - Adds all agent nodes to the graph.\n",
    "    - Defines routing and conditional edges for dynamic flow control.\n",
    "    - Compiles and returns the final executable graph.\n",
    "\n",
    "    Returns:\n",
    "        Graph: A compiled LangGraph app instance ready for use.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the graph with the shared state type\n",
    "    graph = StateGraph(State)\n",
    "\n",
    "    # Add All Agent Nodes\n",
    "    graph.add_node(\"get_user_profile\", get_user_profile)       # Fetch or initialize user data\n",
    "    graph.add_node(\"router\", router)                           # Routes user queries to agents\n",
    "    graph.add_node(\"general\", general)                         # Handles general/fallback queries\n",
    "    graph.add_node(\"course_recommender\", course_recommender)   # Suggests learning courses\n",
    "    graph.add_node(\"project_recommender\", project_recommender) # Recommends projects\n",
    "    graph.add_node(\"interview_coach\", interview_coach)         # Prepares user for interviews\n",
    "    graph.add_node(\"learning_path_advisor\", learning_path_advisor) # Suggests learning paths\n",
    "    graph.add_node(\"resume_builder\", resume_builder)           # Builds or optimizes resumes\n",
    "    graph.add_node(\"skill_analyzer\", skill_analyzer)           # Analyzes user skills\n",
    "    graph.add_node(\"resume_parser\", resume_parser)             # Parses resume content\n",
    "    graph.add_node(\"job_description_parser\", job_description_parser) # Parses job descriptions\n",
    "\n",
    "    # Define Graph Edges and Logic\n",
    "    \n",
    "    # Entry flow: start from profile setup ‚Üí router\n",
    "    graph.add_edge(START, \"get_user_profile\")\n",
    "    graph.add_edge(\"get_user_profile\", \"router\")\n",
    "\n",
    "    # Conditional routing from router to the appropriate agent\n",
    "    graph.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda state: (\n",
    "            state[\"agent_action\"]\n",
    "            if state[\"agent_action\"] not in [\"interview_coach\", \"resume_builder\"]\n",
    "            else \"parser\"\n",
    "        ),\n",
    "        {\n",
    "            \"course_recommender\": \"course_recommender\",\n",
    "            \"project_recommender\": \"project_recommender\",\n",
    "            \"parser\": \"resume_parser\",\n",
    "            \"learning_path_advisor\": \"learning_path_advisor\",\n",
    "            \"skill_analyzer\": \"skill_analyzer\",\n",
    "            \"general\": \"general\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Parser flow: resume ‚Üí job description ‚Üí specific agent\n",
    "    graph.add_edge(\"resume_parser\", \"job_description_parser\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"job_description_parser\",\n",
    "        lambda state: state[\"agent_action\"],\n",
    "        {\n",
    "            \"resume_builder\": \"resume_builder\",\n",
    "            \"interview_coach\": \"interview_coach\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Define Endpoints\n",
    "    for end_node in [\n",
    "        \"course_recommender\",\n",
    "        \"project_recommender\",\n",
    "        \"interview_coach\",\n",
    "        \"learning_path_advisor\",\n",
    "        \"resume_builder\",\n",
    "        \"skill_analyzer\",\n",
    "        \"general\",\n",
    "    ]:\n",
    "        graph.add_edge(end_node, END)\n",
    "\n",
    "    # Compile Final Graph App\n",
    "    app = graph.compile()\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05b276ef-513a-47c2-b2bf-69ffc29f2227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../conversation_manager.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../conversation_manager.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from utils.llm import get_llm\n",
    "from graph_builder import build_graph\n",
    "\n",
    "# Initialize LLM instance\n",
    "llm = get_llm()\n",
    "\n",
    "# Initialize LangGraph Multi-Agent\n",
    "app = build_graph()\n",
    "\n",
    "# Exit Detection Prompt\n",
    "exit_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a conversation manager.\n",
    "    Given the user's latest message, decide if the user wants to end the conversation.\n",
    "    \n",
    "    If the user clearly says something like \"bye\", \"thank you\", \"stop\", \"exit\", \"goodnight\", etc., \n",
    "    respond ONLY with the single word: \"exit\".\n",
    "    Otherwise, respond ONLY with the word: \"continue\"\n",
    "    \n",
    "    User message:\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine prompt with the language model\n",
    "exit_chain = exit_prompt | llm\n",
    "\n",
    "# Initialize Memory\n",
    "memory = []          # Stores dialogue history\n",
    "memory_summary = \"\"  # Compressed summary of recent context\n",
    "\n",
    "# Main Conversation Loop\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # Check if user wants to end the conversation\n",
    "    should_continue = exit_chain.invoke({'user_input': user_input}).content.strip()\n",
    "\n",
    "    if should_continue == \"exit\":\n",
    "        print(\"AI: Goodbye üëã\")\n",
    "        break  # Exit loop gracefully\n",
    "\n",
    "    # Retain only last 10 messages for context\n",
    "    memory = memory[-10:]\n",
    "\n",
    "    # If there‚Äôs existing conversation, summarize it\n",
    "    if memory:\n",
    "        summary_prompt = ChatPromptTemplate.from_template(\n",
    "            \"Summarize the key context of this conversation in 5 concise sentences:\\n\\n{conversation}\"\n",
    "        )\n",
    "        formatted = \"\\n\".join(memory)\n",
    "        chain = summary_prompt | llm\n",
    "        memory_summary = chain.invoke({\"conversation\": formatted}).content.strip()\n",
    "    else:\n",
    "        memory_summary = \"\"\n",
    "\n",
    "    # Build the current conversation state\n",
    "    state = {\n",
    "        \"input_text\": user_input,\n",
    "        \"memory_summary\": memory_summary,\n",
    "    }\n",
    "\n",
    "    # Invoke the main LangGraph app (routes to the right agent)\n",
    "    result = app.invoke(state)\n",
    "    response = result.get(\"response\", \"(No response)\")\n",
    "\n",
    "    # Display AI response\n",
    "    print(f\"AI: {response}\\n\")\n",
    "\n",
    "    # Save latest messages in memory\n",
    "    memory.append(f\"User: {user_input}\")\n",
    "    memory.append(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8974f79-a470-4250-92a7-7e1efd686593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
